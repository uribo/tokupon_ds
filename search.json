[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "データ分析入門",
    "section": "",
    "text": "このページは徳島大学デザイン型AI教育研究センターが 開催する、小中高生を対象にした「とくぽんAI塾 2022」のコースの一つである「データ分析入門」 の資料置き場です。\nコースは基礎編と発展編の2つに分けられます。基礎編では、データ分析に必要な知識・背景の理解のための 素養を身につけることを目指します。発展編ではデータ分析の問題への挑戦として、回帰と分類問題について 取り組みます。 このコースでは、基礎から発展まで通して R言語を使ったデータ分析を行います。\nまずデータ分析についての大まかな内容とデータ分析で扱われる課題について第1章で学びます。 次に第2章では、データの種類と扱い方、表現方法を身につけます。 第3章ではデータを要約ようやくし、伝えやすくするための方法を紹介します。 ここでは特に１つの変数へんすうについて扱います。 第4章は２つの変数の関係を調べるための相関について理解を深めます。 基礎編の最終章となる第5章では、データ分析に欠かせないデータのグラフ化、可視化のノウハウを学びます。 ここでは一般的な統計グラフの他に地図による表現についても紹介します。 続く発展編では、回帰と分類についてそれぞれ課題を設定し、Rによるプログラミングとその出力の理解を目指します。\n\n\n高等学校情報科における共通必履修科目「情報Ⅰ」を学習する高校生、また将来学習することになる中学生。\nデータ分析について簡易な内容で学びたい社会人\n\n\n\n統計の基礎となる確率\nデータ分析に欠かせない行列、線形代数\nRプログラムの解説… 付録で簡単なR言語の導入を行いますが、コース内でのRコードの説明は最小限にとどめています。Rについて詳しく知りたい方は付録および付録の参考文献をご覧ください。\n\n初歩の数学の範囲で説明可能な内容を扱うことを目指します。\n\n\n\n\nとくぽんAI塾2022のテーマは「動物園」です。 そこでこのコースでも動物が登場します。\n\n\n\n徳島大学マスコットキャラクターの「とくぽん」が解説を行います。 とくぽんによる解説には次の種類があります。\n\n\n\n\n\n\nノート\n\n\n\n全般的な補足をコメントするよ。\n\n\n\n\n\n\n\n\n練習問題\n\n\n\nとくぽんからの問題だよ。これまでの内容をおさらいして考えてみてね。\n\n\n\n\n\n\n\n\n警告\n\n\n\n注意が必要な事柄がある場合に説明をするよ。\n\n\n\n\n\nこの内容が分かりにくかった、読めない漢字があったときには 気軽にコメントいただけると改善のために役立ちます。 コメントは GitHub issuesもしくはフォームから投稿をお願いします。\n\n\n\n\nR version 4.2.1\nmacOS Monterey 12.4\n\nこのページはQuartoを使って作成されています。\n\n\n\nBinder\n\n\nこのコースで扱っているRプログラムの内容は、binderによってウェブブラウザ上で試せます。 上記のボタンをクリックすることでbinder上のRStduio Serverが起動します。 （起動に時間がかかることがあります） これによりブラウザ上でRを動かすことができます。 必要なデータ、パッケージはすでにインストールされている状態です。 資料のqmdファイルを開き、内容をなぞる、変更してRを動かしてみてください。 ウェブブラウザで行った変更はブラウザを閉じるとリセットされます。\nページ中のRのコードは下記のようにコードブロックで表示しています。 このコードブロックは右上にカーソルを移動させたときに表示されるアイコンをクリックすることで 内容がコピーされます。また、一部のコードについては非表示の状態のものもあります。 コードを表示とある場合、クリックによってコードが表示されます。\n\nrenvによるパッケージ管理、GitHub actionsによるページのビルドを行っています。\n\n\n\nMIT"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  はじめに",
    "section": "",
    "text": "私たちは日常中で多くのデータに触れながら暮らしています。 データを扱う計算機の処理性能の向上やインターネット回線の高速化、 そしてスマートフォンの普及により、ビッグデータと呼ばれる莫大な量のデータが身の回りに溢れています。\nデータと触れている、といってもデータは実体がなく、認識しづらいものです。 データとは一体何でしょうか。 辞書を引いて確認してみますと、「判断や立論のもとになる資料・情報・事実」とあります。 物事を判断、何かについて議論するための材料といったところでしょうか。 材料であるデータは、ある対象について調査、観測や実験などを行うことで得られます。 そこにはたくさんの情報が含まれていることが多いです。\n例えば、ある個人の一日の行動を調査し、データ化するとします。 その場合、生年月日や氏名、住所や一日の行動（何時にどこへいたか）などが情報として扱われます1。 一方でこうしたデータを蓄積ちくせきしただけでは、情報の羅列られつとなり、あまり意味がありません。 集めたデータをもとにして、分析を行うことで見えてくるものがあります。 データから得られる情報を読み解き、データを人間が利用できる形に変換・処理を行うことで対象についての理解や予測を目指す手続きを「データ分析」と呼びます。\nデータ分析には次の目的があります。\n\nデータを要約ようやくすること\nデータの意味・関係を説明すること\n新たに得られるデータに対する予測を行うこと\n\n要約とは物事の中心となる大切な部分を短くまとめることです。 一般的にデータ分析の対象となるデータは膨大ぼうだいです。 そのため一つ一つのデータを見ていくことは難しいです。 そこでデータを要約する方法として代表値によるデータの集約やグラフによるデータ可視化が行われます。 この方法について、コースの中でも第3章と第5章で扱います。\n２つ目の目的として、データがもつ意味やデータに含まれる値の関係性を説明することがあります。 例えば、動物園で飼育されるペンギンの各個体について、体の部位を測定したデータを集めたとします。 そのとき、体の部位ごとにどのような意味、関係があるかを説明する場合、データ分析が役立ちます。 これについては第4章で議論します。\nまたデータを説明するためにはグラフ上にデータを投影することも有効な手段となります。 データ可視化と呼ばれる手法はデータ分析の歴史とともに発展してきました。 第5章でさまざまなデータ可視化の方法を見ていくとともに実際にグラフを作る方法を学びます。\nデータの関係を説明する簡単な例をみてみましょう。 次に示す 図 1.1 は、ペンギンの各個体の大きさを記録したデータをグラフ化したものです。 この図からどのようなことが言えるでしょうか。\n\n\nコードを表示\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\np <- \n  ggplot(penguins, aes(flipper_length_mm, bill_length_mm)) +\n  xlab(\"翼の長さ(mm)\") +\n  ylab(\"口ばしの長さ(mm)\") +\n  labs(title = \"ペンギンの体の大きさの関係\")\n\np + \n  geom_point()\n\n\n\n\n\n図 1.1: ペンギンの体の大きさの関係\n\n\n\n\n図 1.1 のようなグラフを散布図（または相関図）と呼びます。 散布図は２つのデータの関係を示すのによく使われます。 ここではグラフの下部と左側に表記がある通り（それぞれx軸、y軸と言います）、 「翼の長さ」と「口ばしの長さ」を示しています。 軸の横に書かれている数値はその大きさです。 一つ一つの点がペンギンの個体を表しています。\n図 1.1 を見ると、翼の長い個体ほど口ばしも長いと言えるような気がします。 そこでデータ分析では「ペンギンの個体は翼の長い個体ほど口ばしも長い」という仮定を置きます。 この仮定を説明するために、データ分析ではデータの間の関係を説明する「モデル」を考えます。\nまた、先ほどのペンギンデータは実は複数のペンギンの種名2について調べたデータだったとします。 このとき、体の部位の関係の説明にペンギンの種名という、もう一つのデータが加わることになります。 そこで 図 1.1 の図に手を入れて、種類ごとに色分けした図を見てみることにします (図 1.2)。\n\n\nコードを表示\nsource(\"scripts/color_palette.R\")\np + \n  geom_point(aes(color = species)) +\n  scale_colour_tokupon(name = \"種名\",\n                       labels = c(\"アデリーペンギン\", \"ヒゲペンギン\", \"ジェンツーペンギン\"))\n\n\n\n\n\n図 1.2: ペンギンの体の大きさの関係を種名別に比較する\n\n\n\n\n図 1.2 では、最初の仮定（翼の長さと口ばしの長さが比例して大きくなる）が変わることはなさそうです。 しかしペンギンの種類によって体の部位の大きさには幅が決まっていそうだ、ということも見えてきました。 具体的にはアデリーペンギン、ヒゲペンギン、ジェンツーペンギンの順番で体の大きさに違いがあるようです。 これも新たな仮定としておきましょう。 この仮定を調べるためのモデルも存在します。 こうしたデータ間の比較ひかく（2つあるいは3つ以上のものを比べ、そこにある違いを考えること）もデータ分析で扱う内容です。\nデータ分析の最後の目的は、新たに得られるデータに対する予測を行うことです。 これまでに集めたデータや構築したモデルから、新たなデータへの予測を行います。 モデルが存在することで、ある程度の未知のデータに対する予測が可能になります。 ペンギンの体の大きさの例で見たように、翼の長さがわかれば、口ばしの長さに対する見通しが立ちます。 また、ある程度の大きさであれば種類まで特定できるかもしれません。\nデータ分析を行うために、数学の知識が活用できます。 特に統計学や機械学習では、数学を用いたデータ分析の手法を扱います。 数学は理系の印象がありますが、データ分析では文理問わず求められる技能なのです。 しかし数学はデータ分析において必須ではありません。 この書籍の中でも高度な数学を用いずにデータ分析を行う方法や、データを表現する可視化の手法について紹介します。\n\n\n\n\n\n\nデータサイエンスとデータサイエンティスト\n\n\n\nデータ分析に加えて、データの処理の実行、データから新たな価値を生み出す分野をデータサイエンスと呼ぶよ。 データ分析の技能だけじゃなくて、データを適切に処理することやデータを活用できることが重要になっているんだね。 また、こうしたデータサイエンスの素養をもつ人はデータサイエンティストと呼ばれるよ。\nデータサイエンスでは情報学と統計学の基礎が求められる一方で、応用先は人や社会であることが多いんだ。 だからこそ文理融合的な学習が必要とされているんだね。\n\n\n\n\nデータ分析はいくつかの作業に分けて考えることができます。 まずデータ分析によって解決したい課題や適切なデータを見つける段階があります。 これらの内容は課題ごとに異なります。 その後、典型的な手順に落とし込むことが可能となります。\n図 1.3 は一般的なデータ分析の手順を示したものです。 まずデータを入手し、コンピュータが扱えるように読み込みます。 続いて、その後の処理が行いやすいように整形を行います。 多くのデータは人間が解釈しやすいように記録されています。 その形はコンピュータやプログラムで利用できる状態でないことがしばしばあります。 また、データ化に伴う不備や正しく読み取れないデータというのも存在します。 こうした問題に対する処理もデータ分析では必要になります。\n\n\n\n図 1.3: データ分析の大まかな流れ\n\n\nデータを正しく読み取り、プログラムで扱いやすい形式に加工したら、 データ分析の主要な部分である加工、可視化、モデルの作業です。 可視化とは、図表を用いてデータを表現することを意味します。 これらの作業は一方向的なものではなく、互いに繋がっています。 例えば、モデルの作成のためにデータを加工する、加工したデータを使って可視化をする、 といった具合です。\nこれらの作業を繰り返し、最終的な伝達が行われます。 データ分析の目的で触れたように、データ分析は行っただけで終わりではありません。 レポートの作成やプレゼンテーションなど、何らかの方法によりその内容を伝えなくてはいけません。\n\n\n\nデータから得られた情報が有効活用された例を2つ紹介します。 まずは1854年にロンドン（イギリス）で発生したコレラの大発生に対する ジョン・スノウによる活躍です。\n当時コレラは未知の疫病えきびょうで多くの死者を出していました。 この原因不明の病いは空気中の粒子や未知の細菌が原因と考えるのが科学者や政府の考えであり、 それに基づく政策が行われていました。 人々が密集するロンドンの街では、下水の整備が追いつかず、排泄物の処理が十分に行われていませんでした。 このことがコレラの流行に繋がると考えた役人は、下水を整備し汚物を川に流すというものでした。 しかしこの政策によってもコレラの患者が減ることはありませんでした。\nコレラの原因と考えられていた空気感染に対して疑問を持っていたジョン・スノウは、地元住民らへの聞き込み調査等を行い、最終的にコレラの発生源が、水道ポンプであると特定しました。 その結論に至るまでにジョン・スノウがとった行動は以下に整理できます。\n\nコレラで亡くなった人の家の周囲環境を調べる\n同じような条件でコレラにかかった人とそうでない人の違いを比べる\n「仮説」をもとにコレラの発症に関係すると考えられる要因について検証する\n\n確証がないとの理由から、残念ながらジョン・スノウが導いた細菌に汚染された水が問題であるとする意見は政府に受け入れられた訳ではありませんでしたが、ジョン・スノウは得られたデータ（患者が使用していた井戸水の位置と井戸水を供給する水道会社）をもとに原因解決のために働きます。 問題となる井戸を特定したり、死者が発生した家で利用される水道会社の比較を行うことで、水の停止を求め、一部の地域ではコレラの感染を抑えることに成功しました。\nジョン・スノウはデータと分析に基づき、問題解決のために働いた人物です。 ジョン・スノウが行ったデータの比較方法や分析は、現代の疫学研究の基礎となるものでした。 そのため彼は現代では疫学の父と呼ばれています。\n\n\n\n\n\n\nジョン・スノウによる地図\n\n\n\nジョン・スノウは住民への聞き込み調査と合わせて、コレラで死亡した人の居住地を地図上にマッピングしたんだ。 図 1.4 に示すように、一人の死者に対して黒い棒グラフを描いて死者が多い地域を強調しようとした試みがされているね。 地図にはさらに井戸の位置も表示されているよ。 これはコレラの流行の原因が、細菌に汚染された水にあると考えるジョン・スノウならではの視点だったのかもしれないね。\n\n\n\n図 1.4: 1854年にジョン・スノウが作成したゴールデン・スクエアのブロード・ストリート周辺における死亡者の状態を示す地 パブリックドメイン https://commons.wikimedia.org/wiki/File:Snow-cholera-map-1.jpg\n\n\n\n\nデータを用いることで医療に貢献した人物として、もう一人、フローレンス・ナイチンゲールの例を挙げます。 近代看護教育の母として知られる人物ですが、効果的なグラフ作成を行った人物でもあります。\nナイチンゲールは1853年から1856年の間に発生していたクリミア戦争において、戦場で負傷した兵士の看護と衛生面の改善に取り組みました。戦争終了後、戦争による死者の原因を分析する中で、戦闘で負った傷が原因で亡くなる兵士よりも、負傷後に何らかの菌に感染した影響で病気となり死亡する兵士のほうが圧倒的に多いことを明らかにしました。 しかし軍はその結果を認めようとはしませんでした。 そこでナイチンゲールはデータをよりわかりやすく、明確に伝えるための工夫としてグラフを作成しました (図 1.5)。\n\n\n\n図 1.5: Nightingale, Florence. A contribution to the sanitary history of the British army during the late war with Russia. London : John W. Parker and Son, 1859. (page 19 (seq. 25)). Repository: Countway Library of Medicine. Institution: Harvard University. アクセス日: 2022年7月6日. リンク: https://nrs.lib.harvard.edu/urn-3:hms.count:1177146?n=25\n\n\nナイチンゲールが示したのは風変わりなグラフでしたが、単純な棒グラフ以上に関心を引きやすい、美しい画像を用意することで、政府の説得を目指したのかもしれません。\nいずれの話も21世紀に入る前のものですが、なぜ今データ分析、データサイエンスが注目されているのでしょうか。 それには冒頭で述べたようにビッグデータの台頭やコンピュータの性能向上、分析手法の進展があげられます。 現代は、ジョン・スノウやナイチンゲールが活躍した時代と比べて、社会のあらゆる分野においてデータやコンピュータを活用することが当たり前になっています。\nデータは「21世紀の石油」と呼ばれるように、ビジネスにおいてもデータ分析を活用した課題解決が前提となっています。 データを経済的な資源として考え、それを保有・活用できる企業が大きく成長しています。 GoogleやAmazon、百度などはビッグデータを利用した企業の一例ですが、これらの企業は現代のデータ駆動型社会において他の企業よりも優位な位置を築いています。"
  },
  {
    "objectID": "intro.html#データグラフに騙されない",
    "href": "intro.html#データグラフに騙されない",
    "title": "1  はじめに",
    "section": "1.2 データ、グラフに騙されない",
    "text": "1.2 データ、グラフに騙されない\n普段の生活の中で、数値やグラフを目にする機会がたくさんあります。 天気予報や学校のテストの成績、スマートフォンやスマートウォッチで記録される歩数（図 1.6）などです。\n\n\n\n図 1.6: スマートフォンに記録される活動量。数値を時間ごとにグラフ化し、一日の活動量と時間帯の関係がわかる\n\n\nこのような数字やグラフを見た時に感じる印象は人それぞれですが、 多くの人が共感するものも存在します。\n次の 図 1.7 は文部科学省が毎年行う「学校保健統計調査」から5歳の幼児（男）における都道府県別の身長・体重の平均値を棒グラフにしたものです。全国で最も順位の低い県は徳島県であることがわかります。全国一位の宮城県と比べると何倍も差があるように見えます。しかしこれはグラフのトリックです。注意して横軸を見てみましょう。\n\n\n\n\n\n図 1.7: 誤解を招きやすいグラフの例。5歳の幼児における都道府県別の平均身長。グラフの横軸が0から始まっていないために値の差が大きく見えてしまう。\n\n\n\n\nこのグラフの横軸は0で始まっていないことに気がついたでしょうか。 これがグラフのトリックを引き起こしている原因です。 横軸が0からの図（図 1.8）と見比べてみましょう。\n\n\n\n\n\n図 1.8: 横軸を0から示した平均身長を示す棒グラフ\n\n\n\n\n先ほどは都道府県間の差が大きく感じたものが、今度はどの県も平坦な様子に思えたのではないでしょうか。 数値が変わったわけではないので、順位に違いはありませんが見た目の印象が大きく違います。 数値で確認すると、全国一位の宮城県の5歳の男児の平均身長は112.8cmで徳島県では110.1cmで、その差は2.7cmです。 図 1.7 で何倍も開きがあるように感じた印象ほどではないと思える数値ではないでしょうか。\n数字やグラフにはある種の説得力が存在します。 目に見えるものが示す内容を鵜呑みにして物事を判断してしまうことは危険です。 テストの点数がクラスの平均よりも低かったからと言って、クラスの上位に含まれていないとは限りません（逆もあります）。 また、最近では一日の新型コロナウィルス感染症の新規感染者数が報道されますが、悲観的になり過ぎる心配はない場合もあります。\n\n\n\n\n\n\nテストの点数がクラスの平均点よりも低くても上位に含まれる？\n\n\n\n40人のクラスで行われたテスト（100点満点）の平均点が48点でした。\nこのとき、点数が45点だった人はクラスの上位20人の中に含まれるでしょうか。\n答えと解説は練習問題を見てね。\n\n\n目に見えるデータやグラフには、それを見せる側の意図が存在します。 平均身長のグラフでみたように、同じデータであっても何をどう示すか、どう解釈するかで印象が変わります。 見せ方を工夫して人を騙そうとするものもあり得るでしょう。 こうしたデータ、グラフに騙されないためには、データに対する素養を鍛えることが重要です。 読み書きをする能力のことをリテラシーと言いますが、データに対するリテラシーを備えておくことが求められています。"
  },
  {
    "objectID": "intro.html#データ分析で扱う問題",
    "href": "intro.html#データ分析で扱う問題",
    "title": "1  はじめに",
    "section": "1.3 データ分析で扱う問題",
    "text": "1.3 データ分析で扱う問題\nデータ分析では「モデル」と呼ばれる考え方\n統計モデルを使って問題の解決に挑みます。\n回帰と分類\n扱う課題が回帰問題か分類問題か\n分類と回帰の問題を解くために使われるアルゴリズムは異なります。\nこのコースでも、発展として簡単な回帰と分類問題に挑戦します。\n\n\n\n\n\n\nR言語について\n\n\n\nこのコースではR言語を使った実習を行うよ。 R言語は統計計算と作図の機能に優れたプログラミング言語の一種だよ。 オープンソース・フリーソフトウェアと言って、誰もが自由に使うことができるんだ。\nR言語に関心を持ったなら、付録の「Rのイロハ」を見てみてね。\nRのインストール方法、簡単な使い方を紹介するよ。"
  },
  {
    "objectID": "intro.html#まとめと課題",
    "href": "intro.html#まとめと課題",
    "title": "1  はじめに",
    "section": "1.4 まとめと課題",
    "text": "1.4 まとめと課題\n\n身の回りにあるデータやグラフを探してみよう。それはどんなものかな？"
  },
  {
    "objectID": "intro.html#参考文献url",
    "href": "intro.html#参考文献url",
    "title": "1  はじめに",
    "section": "1.5 参考文献・URL",
    "text": "1.5 参考文献・URL\n\n(西内啓 2013)\n(江崎貴裕 2020)\n(竹内薫 2014)\n(著 2018)\n(アルベルト・カイロ著(薮井真澄訳) 2020)\n(マイケル・フレンドリー と 訳 2021)\n小・中学生のための統計学習 まなぼう統計 https://www.toukei.metro.tokyo.lg.jp/manabou/ma-index.htm\nなるほど統計学園 https://www.stat.go.jp/naruhodo/ … 総務省統計局による、統計について興味・関心を持ってもらうための統計学習サイト\n青空文庫 コレラの伝染様式について https://www.aozora.gr.jp/cards/001600/files/53757_67624.html\n\n\n\n\n\nマイケル・フレンドリーハワード・ウェイナー 著, と 訳. 2021. データ視覚化の人類史 : グラフの発明から時間と空間の可視化まで. 青土社. http://id.ndl.go.jp/bib/031736628.\n\n\n江崎貴裕. 2020. 分析者のためのデータ解釈学入門 : データの本質をとらえる技術. ソシム. http://id.ndl.go.jp/bib/030791751.\n\n\n竹内薫. 2014. 統計の9割はウソ : 世界にはびこる「数字トリック」を見破る技術. 徳間書店. http://id.ndl.go.jp/bib/025194412.\n\n\n著. 2018. データサイエンス入門. 岩波新書 新赤版 ; 1713. 岩波書店. http://id.ndl.go.jp/bib/028897021.\n\n\nアルベルト・カイロ著(薮井真澄訳). 2020. グラフのウソを見破る技術 : マイアミ大学ビジュアル・ジャーナリズム講座. ダイヤモンド社. http://id.ndl.go.jp/bib/030421662.\n\n\n西内啓. 2013. 統計学が最強の学問である : データ社会を生き抜くための武器と教養. ダイヤモンド社. http://id.ndl.go.jp/bib/024193446."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  データの種類と表現方法",
    "section": "",
    "text": "データ分析を行う上では「データ」のことを知らなくては進めません。 データの種類は数値だけではありません。さらに数値にもいくつかのタイプがあります。 最近ではビックデータや機械学習の普及によりログデータや画像、動画ファイルをデータとして扱う機会も増えていますが、ここではデータの種類として古くから存在する表形式のデータを例に解説します。"
  },
  {
    "objectID": "data.html#データの種類",
    "href": "data.html#データの種類",
    "title": "2  データの種類と表現方法",
    "section": "2.1 データの種類",
    "text": "2.1 データの種類\nデータと言われて思い浮かべるものはなんでしょうか。 ここではデータをさまざまな計測や観察により得られる情報のことを示します。 対象から情報を引き出したものと言い換えることもできます。 多くは数値の形をしていますが、文字列である場合もあります。 データの例をあげてみましょう。 ある動物について、体の一部の大きさや体重を測る、雌雄を調べる。 これらはデータの一つです。 体の部位や体重は数値によって観測されますが、雌雄は「雄」や「雌」という文字列で記録されるのが一般的です。\nRを使ったデータの記述方法を紹介します。 ここではある動物の種類についての体重と分類群を調べた結果を入力します。 c()関数1の括弧の中（引数ひきすう）に値である数値や文字列を記述します。 値と値の間にカンマ , を入力すると複数の値を記述することになります。 数値は直接入力できますが、文字列を与えるときは引用符 \" で文字列を囲む必要があります。\n\n# ある動物の種類についての体重と分類群を調べました\n# 複数の値を並べるときは カンマ , を使います\nc(6, 3.5, 5.4)\n\n[1] 6.0 3.5 5.4\n\n# 文字列は 引用符 \" で囲みます\nc(\"食肉類\", \"鳥類\", \"食肉類\")\n\n[1] \"食肉類\" \"鳥類\"   \"食肉類\"\n\n\n「複数の動物の体重」のように、共通の手法によって得られた値のことを変数へんすうといいます。 動物の体重は、個体や種類が違うと値も変わります。 このように対象によって数値が変わるもの、変化する値を意味します。\n\n2.1.1 変数の性質の違い\n体重を記録するときは数値を用いました。 このように数量を表す変数のことを量的変数といいます。 数値からなる変数なので、平均を求めたり大きい順番に並び替えるといった処理が可能です。\n量的変数の場合、数値の種類によってさらに離散変数と連続変数に分類できます。 とり得る値が一定の間隔によりバラバラな変数を離散りさん変数と呼びます。 例えばサイコロの出目は一般的に1から6までの整数であるため、離散変数です。 また動物を1頭、2頭と数えた個体数も同じです。\n離散型の量的変数に対し、連続値で表現される変数を連続変数といいます。 3.5\\(kg\\)、5.4\\(kg\\)のように表現される体重は連続変数です。\nでは雌雄や分類群はどのように記録するのが適切でしょうか。 これらは数量として扱いにくいものです。 「雄」や「雌」、「鳥類」や「霊長類」という具合に項目を変数として扱う場合、 それは質的変数またはカテゴリ変数と呼ばれます。 質的変数は量的変数のように足し算や引き算といった計算ができないのが特徴です。\n\n\n\n\n\n\n\n測定の尺度\n\n\n\n変数の性質により、量的変数と質的変数をより細かく分類することもあるよ。 尺度水準と呼ばれる基準を用いると、量的変数は間隔尺度と比例尺度に、質的変数は名義尺度と順序尺度に分けて考えることができるんだ。それぞれの特徴を説明するね。\n\n比例尺度: 量的変数のうち値の比それ自体に意味のある尺度。\n間隔尺度: 量的変数で値の差自体に意味のある尺度。例) 華氏で記録した温度\n順序尺度: 質的変数で項目に順序があるもの。大小の比較ができるが演算には意味を持たない。代表値は最頻値や中央値で表される。例) 動物の保全状況\n名義尺度: 質的変数のうち、順序がないもの。値の比較や演算に意味を持たず、数値を単なる名前として対象に割り振る。このとき代表値の指標としては最頻値のみが利用できる。名義尺度だけで与えられるデータをカテゴリデータと呼ぶこともある。例) 雌雄、動物の分類群\n\n\n\nデータの種類に応じて名前がついている理由は、 データの種類によって適切なデータ分析の手法が異なるためです。 データ分析を行う際は、データがどの種類の変数なのか意識することが大切です。"
  },
  {
    "objectID": "data.html#データフレーム",
    "href": "data.html#データフレーム",
    "title": "2  データの種類と表現方法",
    "section": "2.2 データフレーム",
    "text": "2.2 データフレーム\nデータ分析の作業においては、データの変数を比較し、関係を調べることが頻繁に行われます。 特定の個体や観測について複数の項目を同時に扱えるようにするために、データを表形式でまとめて表現します。 これを表データまたはデータフレームと呼びます。\nデータフレームの例として、いくつかの動物の体の大きさ（体長）と体重の記録をデータフレームにまとめてみましょう。 データフレームでは個人や個体、観測といったデータを一つの行にまとめます。 レッサーパンダの体長と体重の行、チンパンジーの体長と体重の行と、それぞれの値を行単位で記録します。 22種類の動物のデータをとった場合は22行、40種の動物についてであれば40行となりますね。 また、動物の分類群や名前や体長、体重といった変数を列として表します。\n\n\n\n\n\nコードを表示\ndf_zoo_subset\n\n\n\n\n\n表 2.1: 5種の動物についての体長・体重のデータフレーム\n\n\n分類群\n動物の名前\n体長(cm)\n体重(kg)\n\n\n\n\n食肉類\nレッサーパンダ\n63.5\n6\n\n\n霊長類\nチンパンジー\n85.0\n60\n\n\n霊長類\nマントヒヒ\n80.0\n20\n\n\n食肉類\nライオン\n250.0\n225\n\n\n鳥類\nフンボルトペンギン\n69.0\n6\n\n\n\n\n\n\n\nデータフレームではデータを横に見たものが行、縦に見たものを列と考えます。 表 2.1 のデータフレームは5行4列のデータフレームといえます。\n\n\n\n\n\n\n表計算ソフトウェアでも表データを扱う\n\n\n\n表計算ソフトウェアにデータを記録するときもデータフレームと同じ形式をとるよ。 ここでは1,2,3といった数字が行、A、B、Cといったアルファベットが列を示しているね。 それぞれの値を記録している場所のことをセルというよ。 これはデータを記録している番地のようなもので、例えば、チンパンジーの体重はC3を参照すれば良いことになるね。\n\n\n\n表計算ソフトウェアで表データを扱う\n\n\n\n\n先ほど5種の動物のデータフレームを示しましたが、データ分析を進めていくには より多くのデータが必要になります。 たくさんのデータがあれば、データから見えてくる傾向・パターンも見えやすくなります。 ここでは22種の動物について、同様の体長、体重を調べたデータを用意しました。 ここからはこの動物データ (表 2.2) を使い、データを調べていくことにします。 このデータはとくしま動物園で 飼育される動物について記録したものです。詳細は付録データセットで解説しています。\n\n2.2.1 Rでのデータフレーム操作\n動物データはcsvファイルと呼ばれるテキストファイルの一種に記録されたデータです。 csvファイルはデータを記録するためのファイル形式として広く使われるもので、 カンマ , によって変数を区切っていくのが特徴です。 データフレーム同様、個体や観測のデータを一つの行にまとめます。 具体的には動物データの中身は次のようになっています。\ntaxon,name,body_length_cm,weight_kg\n食肉類,レッサーパンダ,63.5,6\n鳥類,ホオジロカンムリヅル,100,3.5\n食肉類,コツメカワウソ,64,5.4\n以下省略...\nRではcsvをはじめとした各種ファイルをデータフレームとして扱うための関数が用意されています。 read.csv()関数でcsvファイルを読み込むには、関数の第一引数にファイルのパス（置き場所）を文字列で与えて実行します。データはdf_zooというオブジェクトに格納され、いつでも表示（参照）できるようになっています。\n\n# dfはデータフレーム(data frame)の頭文字から\n# 動物データの読み込み\ndf_zoo <-\n  read.csv(\"data-raw/tokushima_zoo_animals22.csv\")\n\n\ndf_zoo\n\n\n\n\n表 2.2: 動物データ\n\n\ntaxon\nname\nbody_length_cm\nweight_kg\n\n\n\n\n食肉類\nレッサーパンダ\n63.5\n6.0\n\n\n鳥類\nホオジロカンムリヅル\n100.0\n3.5\n\n\n食肉類\nコツメカワウソ\n64.0\n5.4\n\n\n鳥類\nカナダガン\n110.0\n6.5\n\n\n霊長類\nチンパンジー\n85.0\n60.0\n\n\n霊長類\nシシオザル\n66.0\n10.0\n\n\n霊長類\nマントヒヒ\n80.0\n20.0\n\n\n食肉類\nピューマ\n168.0\n80.0\n\n\n齧歯類\nカピバラ\n134.0\n66.0\n\n\n食肉類\nライオン\n250.0\n225.0\n\n\n鳥類\nアフリカハゲコウ\n130.0\n9.0\n\n\n偶蹄類\nシロオリックス\n175.0\n220.0\n\n\n食肉類\nミーアキャット\n31.0\n0.9\n\n\n食肉類\nシンリンオオカミ\nNA\n30.3\n\n\n鳥類\nアンデスコンドル\n1.2\n15.0\n\n\n食肉類\nホッキョクグマ\n250.0\n410.0\n\n\n霊長類\nリスザル\n35.0\n1.1\n\n\n鳥類\nフンボルトペンギン\n69.0\n6.0\n\n\n鯨偶蹄類\nラマ\nNA\n140.0\n\n\n奇蹄類\nポニー\nNA\nNA\n\n\n齧歯類\nモルモット\n40.0\n1.5\n\n\n鯨偶蹄類\nヒツジ\nNA\nNA\n\n\n\n\n\n\n\n上記のコマンドの実行により、データフレームが出力されたかと思います。 一行目の出力が変数を示しています。これは列の名前（列名）とも呼ばれます。 データフレームをプログラミング言語で扱うときはこの列名にはできるだけ英語やローマ字を使ったものにしましょう。 漢字やひらがなを使うと意味がわかりやすいですが、海外で開発されたRのようなプログラムは日本語の扱いに不自由な点があるためです。 ここでも次のように動物データの列名を日本語から英語に変えてあります。\n\ntaxon: 動物の分類群\nname: 動物の種名\nbody_length_cm: 体長(単位はcm)\nweight_kg: 体重(単位はkg)\n\n変数を参照するにはドル記号 $を使います。\n\n# データフレーム中の変数を参照するにはドル記号 $ に続けて変数名を与えます。\ndf_zoo$name\n\n [1] \"レッサーパンダ\"       \"ホオジロカンムリヅル\" \"コツメカワウソ\"      \n [4] \"カナダガン\"           \"チンパンジー\"         \"シシオザル\"          \n [7] \"マントヒヒ\"           \"ピューマ\"             \"カピバラ\"            \n[10] \"ライオン\"             \"アフリカハゲコウ\"     \"シロオリックス\"      \n[13] \"ミーアキャット\"       \"シンリンオオカミ\"     \"アンデスコンドル\"    \n[16] \"ホッキョクグマ\"       \"リスザル\"             \"フンボルトペンギン\"  \n[19] \"ラマ\"                 \"ポニー\"               \"モルモット\"          \n[22] \"ヒツジ\"              \n\n\nファイルを用意せずに、直接データフレームの生成もできます。 これにはdata.frame()関数とc()関数を使います。 data.frame()関数の引数に変数名 = 値の形式でデータを与えていきます。 文字列の変数は引用符 \" で囲む点、データの区切りにはカンマ , を使う点に注意してください。\n\ndata.frame(\n  taxon = c(\"食肉類\", \"鳥類\", \"食肉類\"),\n  name = c(\"レッサーパンダ\", \"ホオジロカンムリヅル\", \"コツメカワウソ\"),\n  body_length_cm = c(6.0, 3.5, 5.4),\n  weight_kg = c(63.5, 100, 64.0))"
  },
  {
    "objectID": "data.html#まとめと課題",
    "href": "data.html#まとめと課題",
    "title": "2  データの種類と表現方法",
    "section": "2.3 まとめと課題",
    "text": "2.3 まとめと課題\n\nデータをとる対象ごとに得られる、共通の手法によって得られた値のことを変数と呼びます。 変数は性質の違いによって分類できます。身近なものを対象に分類をしてみましょう。"
  },
  {
    "objectID": "data.html#参考文献url",
    "href": "data.html#参考文献url",
    "title": "2  データの種類と表現方法",
    "section": "2.4 参考文献・URL",
    "text": "2.4 参考文献・URL\n\n(北川源四郎 と 内田誠一 2021)\n\n\n\n\n\n北川源四郎竹村彰通 編, と 内田誠一孝忠大輔. 2021. 教養としてのデータサイエンス = Data Science as the Liberal Arts. データサイエンス入門シリーズ. 講談社. http://id.ndl.go.jp/bib/031484010."
  },
  {
    "objectID": "summary_statistics.html",
    "href": "summary_statistics.html",
    "title": "3  データの特徴を捉える",
    "section": "",
    "text": "データ分析の目的の一つに「データを要約すること」があることを示しました。 それでは実際に、データの要約に取り組んでみましょう。 例として動物データの体長を表示します。\nこのデータの特徴として言えることは何でしょうか？ 動物データに含まれるわずか22件の数値でも、こうした数値の羅列からデータの特徴を説明することは困難です。\nデータ分析で扱うデータの件数は数千、数万となる場合もあり、一つ一つデータを見ていくことも 現実的ではありません。 そこでデータを要約するために記述統計量（要約統計量）の計算やデータの可視化が行われます。 記述統計量はデータ全体を表現する代わりとしてデータを要約したものとして機能します。 記述統計量は大きく分けるとデータの位置を示す値を提供する代表値とデータのばらつきを説明する値の2つに考えられます。 記述統計量を組み合わせてデータの分布を考えることで、データのすべてを説明しなくても十分にデータの内容を伝えることが可能になります。 データの可視化はデータを値そのものとして表現するのではなく、グラフやチャートを用いて説明を行うものです。 記述統計量では失われてしまう情報も、グラフ上に投影することで効果的に示せる可能性があります。\nこの章では複数のRパッケージを利用します。 次のコマンドを実行し、利用できる状態にしておきましょう。"
  },
  {
    "objectID": "summary_statistics.html#データの位置を示す代表値-平均値中央値最頻値",
    "href": "summary_statistics.html#データの位置を示す代表値-平均値中央値最頻値",
    "title": "3  データの特徴を捉える",
    "section": "3.1 データの位置を示す代表値: 平均値、中央値、最頻値",
    "text": "3.1 データの位置を示す代表値: 平均値、中央値、最頻値\n数値の傾向を捉えるには、その値が分布する位置を考えることが重要になります。 そこで手始めに複数の数値の性質や特徴をよく表す代表値を調べてみましょう。 代表値によるデータの要約は、データに含まれる数値が位置するところについて大まかに傾向を把握するために用いられます。 代表値という名前の通り、数値によるデータの表現方法となります。\n代表値によるデータの要約方法にはさまざまなものがあります。代表的なものは平均値の計算です。 平均値の他に中央値、最頻値が代表値としてしばしば使われます。 それぞれの特徴をみていきましょう。\n\n3.1.1 平均値\nまずは代表値の代表として平均値を紹介します。 平均値にも複数の種類が存在しますが、ここではより一般的な算術平均を平均値の例として扱います1。 算術平均とは、2個以上のデータ（データの数を\\(N\\)とします）があるとき、そのすべての数値を足し合わせて\\(N\\)で割った値のことです。\n\n# 1,3,5,7,10の平均を求めましょう\nx <- c(1, 10, 5, 3, 7)\n# まずは対象の数値を足し合わせます\nsum(x)\n\n[1] 26\n\n# 次に数値の数(5)によって足し合わせた数値を割り算します\nsum(x) / length(x)\n\n[1] 5.2\n\n# mean()関数を用いて平均値を計算することもできます。\nmean(x)\n\n[1] 5.2\n\n\n平均値はその言葉の通り、データの真ん中あたりを示す代表値です。 しかし、「あたり」という点に注意してください。 平均値は必ずしもデータの真ん中を示す値ではありません。\n平均値を扱うときは外れ値はずれちの影響を受けやすい性質があるを理解しておきましょう。 外れ値とはデータの中の極端に大きい・小さい値のことです。 次に示す、動物データの一部の動物の体重について平均値がどのくらいになるか考えてみましょう。\n\ndf_zoo_subset <- \n  df_zoo |> \n  arrange(weight_kg) |> \n  filter(name %in% c(\"ミーアキャット\", \"リスザル\", \"モルモット\", \"コツメカワウソ\", \"ホッキョクグマ\")) |> \n  select(name, weight_kg)\n\ndf_zoo_subset\n\n\n\n\n\nname\nweight_kg\n\n\n\n\nミーアキャット\n0.9\n\n\nリスザル\n1.1\n\n\nモルモット\n1.5\n\n\nコツメカワウソ\n5.4\n\n\nホッキョクグマ\n410.0\n\n\n\n\n\n\n\n# 動物データの体重の平均はどのくらい？\ndf_zoo_subset$weight_kg\n\n[1]   0.9   1.1   1.5   5.4 410.0\n\n\n平均値は 83.78 です。 この平均よりも小さな動物は4種もいたにも関わらずです。 この値をデータの真ん中と見なしても問題ないでしょうか。\nデータを見ると一番体重の大きなホッキョクグマが410kgで、二番目に大きな動物とも404.6kgも差があります。 平均値が大きく釣り上げられてしまった原因は、ホッキョクグマの体重が他の動物に比べて極端に大きな値、外れ値であったためです。 ホッキョクグマを除いたときの平均値は2.225となります。 このように平均値はデータの中の外れ値によって大きく左右される特徴があり、注意してください（図 3.1）。\n\n\n\n図 3.1: 平均値は外れ値の影響を受けやすい\n\n\n\n\n3.1.2 中央値\n中央値は、すべてのデータを大きさの順番に並べたとき、大きい方と小さい方のちょうど真ん中にくる値を指します。 例えば得られている数値が1, 10, 5, 3, 7の場合には数値の数は5個なので、その真ん中の順位は3番目の値になります。 この真ん中の順位にくる数値を中央値とします。\n\n# xの数値は大きさの順番になっていないので並び替える\nsort(x)\n\n[1]  1  3  5  7 10\n\nsort(x)[3]\n\n[1] 5\n\nmedian(x)\n\n[1] 5\n\n\n中央値はデータの値に関わらず、順番だけを気にするために外れ値が含まれている場合でも影響を受けません。 先ほどの動物データの一部に対しても中央値を求めましょう。\n\nmedian(df_zoo_subset$weight_kg)\n\n[1] 1.5\n\n\n一方、数値の個数が偶数のときには真ん中の数を決めるのに悩んでしまいます。 例えば4つの数値からなるデータの中央値を求めようとすると、真ん中は2.5番目となってしまいます。データの中には2.5番目の値は含まれません。 このときは2番目と3番目の値の平均を中央値として利用します。\n\n# データの個数が偶数の場合の中央値の求め方\nx <- c(1, 2, 4, 6)\n\nmean(c(x[2], x[3]))\n\n[1] 3\n\n# median()関数で中央値を求められる\nmedian(x)\n\n[1] 3\n\n\n\n\n3.1.3 四分位点\n中央値の考え方を拡張したものとして四分位点があります。 これはデータを小さい方から並び替えたとき、データ全体を均等な数からなる4つのグループに分ける3つの点（値）のことを指します。 各グループ区切りの値となる点をそれぞれ第1四分位点（25パーセンタイル)）、第2四分位点（50パーセンタイル）、第3四分位点（75パーセンタイル）と呼びます。 第2四分位点はデータの値を並び替えたときの真ん中となる値、つまり中央値です(図 3.2)。 また、パーセンタイルというのは値を小さい方から並び替えたときの最後の値の位置を100としたときの四分位点の位置を示す値です。 つまり最小値は0パーセンタイル、最大値は100パーセンタイルとなります。\n\n\n\n図 3.2: 四分位点のイメージ\n\n\nデータの半分が含まれる第1四分位点から第3四分位数までの範囲のことを四分位範囲と呼びます。 四分位範囲は第3四分位点から第1四分位点の値を引くことで求められます。\nペンギンデータの翼の長さ (flipper_length_mm)について四分位点を確認しましょう。 まずはおさらいとして中央値を求めます。\n\npenguins$flipper_length_mm\n\n  [1] 181 186 195  NA 193 190 181 195 193 190 186 180 182 191 198 185 195 197\n [19] 184 194 174 180 189 185 180 187 183 187 172 180 178 178 188 184 195 196\n [37] 190 180 181 184 182 195 186 196 185 190 182 179 190 191 186 188 190 200\n [55] 187 191 186 193 181 194 185 195 185 192 184 192 195 188 190 198 190 190\n [73] 196 197 190 195 191 184 187 195 189 196 187 193 191 194 190 189 189 190\n [91] 202 205 185 186 187 208 190 196 178 192 192 203 183 190 193 184 199 190\n[109] 181 197 198 191 193 197 191 196 188 199 189 189 187 198 176 202 186 199\n[127] 191 195 191 210 190 197 193 199 187 190 191 200 185 193 193 187 188 190\n[145] 192 185 190 184 195 193 187 201 211 230 210 218 215 210 211 219 209 215\n[163] 214 216 214 213 210 217 210 221 209 222 218 215 213 215 215 215 216 215\n[181] 210 220 222 209 207 230 220 220 213 219 208 208 208 225 210 216 222 217\n[199] 210 225 213 215 210 220 210 225 217 220 208 220 208 224 208 221 214 231\n[217] 219 230 214 229 220 223 216 221 221 217 216 230 209 220 215 223 212 221\n[235] 212 224 212 228 218 218 212 230 218 228 212 224 214 226 216 222 203 225\n[253] 219 228 215 228 216 215 210 219 208 209 216 229 213 230 217 230 217 222\n[271] 214  NA 215 222 212 213 192 196 193 188 197 198 178 197 195 198 193 194\n[289] 185 201 190 201 197 181 190 195 181 191 187 193 195 197 200 200 191 205\n[307] 187 201 187 203 195 199 195 210 192 205 210 187 196 196 196 201 190 212\n[325] 187 198 199 201 193 203 187 197 191 203 202 194 206 189 195 207 202 193\n[343] 210 198\n\nmedian(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 197\n\n\nRではquantile()関数を使い四分位点を求めます。 また、summary()関数で出力される値からも四分位点を確認できます。\n\nquantile(penguins$flipper_length_mm, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n 172  190  197  213  231 \n\n\nquantile()関数の出力の25%、50%、75%の表示がそれぞれ第1四分位点、第2四分位点、第3四分位点です。 50%が中央値と同じ値になっている点を確認できました。\n\n続いてsummary()関数の出力結果を見てみます。 こちらは1st Qu.、Median、3rd Qu.が該当する項目です。 Qu.は四分位点を意味する英語のQuantileに由来する表記です。\n\nsummary(penguins$flipper_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  172.0   190.0   197.0   200.9   213.0   231.0       2 \n\n\n平均値や中央値ではデータの位置を示す値として一つの値しかわからなかったのに対して、四分位点を用いることで、より多くの情報を得ることができるようになりました。 この四分位点を利用したデータの視覚的な表現方法として箱ヒゲ図があります。 箱ヒゲ図についてはこの章で後ほど登場します。\n\n\n3.1.4 最頻値\n最頻値はデータの中で最も頻繁に出現する値のことを言います。 クラスのテストの点数で、96点の人が3人と最も多かったとき、最頻値は96です。ただし92点の人が同様に3人いたときには96、92が最頻値となります。\n\nx <- \n  c(73, 58, 96, 61, 87, 54, 92, 92, 63, 80,\n    92, 59, 77, 96, 62, 64, 64, 59, 76, 96)\n\n# 各点数の人数を求めます\ntable(x)\n\nx\n54 58 59 61 62 63 64 73 76 77 80 87 92 96 \n 1  1  2  1  1  1  2  1  1  1  1  1  3  3 \n\n# 最頻値を求めます\nnames(which(table(x) == max(table(x))))\n\n[1] \"92\" \"96\"\n\n\n上記の例は変数が離散変数の場合の最頻値の求め方でした。 連続変数の場合も手順は変わりませんが、数値を適当な間隔でまとめた階級を設定することで判断することがあります。 これについては後ほど、度数分布表を紹介するときに説明します。\nデータの位置を示す代表値3種類を説明しました。 それではデータの特徴を捉えるのに、平均値、中央値、最頻値のどれを使うのが適切でしょうか。 よく使われるのは平均値ですが、だからと言って平均値がどのような時にも優れているわけではありません。 扱うデータの内容、注目する事柄によって重要な代表値は変わってきます。 前の章で、テストの平均点よりも低かった場合の位置について考えましたが、 そのとき中央値を計算していれば、平均よりも低い点であってもクラスの上位に含まれる可能性があることがわかったはずです。\n\n\n\n\n\n\n動物データの代表値を計算しよう\n\n\n\n動物データに対して平均値や中央値、最頻値を求めてみよう。 Rにはここで紹介したmean()やmedian()以外にも 代表値の算出を行う関数が用意されているよ。 それらについて調べて実行してみよう。\nコードの例と解説は練習問題をみてね。"
  },
  {
    "objectID": "summary_statistics.html#データのばらつき",
    "href": "summary_statistics.html#データのばらつき",
    "title": "3  データの特徴を捉える",
    "section": "3.2 データのばらつき",
    "text": "3.2 データのばらつき\n代表値によって、データが分布する大まかな位置を知ることができるようになりました。 一方で外れ値を含む平均値や単純な頻度で求める最頻値のように、分布の形を推定することはできません。 外れ値によって中心がずれているかもしれませんし、最頻値が中心であるという保証はないのです。\nそこで今度はデータのもつばらつきを考えてみます。 データは代表値から離れて分布しているのか、代表値の周辺に集中しているのか。 データの大まかな中心としての代表値とそのばらつきを知ることで、データの分布についておおよその傾向が掴めるようになります。\nばらつき具合を数値で表現する方法として代表的なものに、範囲、分散、標準偏差があります。 ここでも動物データを例にして算出方法をみていきましょう。\n\n3.2.1 範囲\n範囲はもっとも単純で、データの最小値と最大値から求めます。 Rでは最小値、最大値を求める関数としてそれぞれmin()関数、max()関数が用意されています。 また、最小値・最大値を同時に出力するrange()関数も利用できます。 これらの関数はいずれも対象の変数を与えることで計算が行われます。\n\n# 動物データの体長について最小値・最大値を求める\n# bl ... body_lengthの略称として使います\nmin_bl <- \n  min(df_zoo$body_length_cm, na.rm = TRUE)\nmin_bl\n\n[1] 1.2\n\nmax_bl <-\n  max(df_zoo$body_length_cm, na.rm = TRUE)\nmax_bl\n\n[1] 250\n\nrange(df_zoo$body_length_cm, na.rm = TRUE)\n\n[1]   1.2 250.0\n\n\n最小値と最大値がわかれば、次のその差を求めます。この値がデータのとりうる範囲となります。 範囲により区間という意味でのデータのばらつきの程度がわかるようになります。\n\n# 動物データの体長の範囲\nmax_bl - min_bl\n\n[1] 248.8\n\n# このやり方でもOK\ndiff(range(df_zoo$body_length_cm, na.rm = TRUE))\n\n[1] 248.8\n\n\n範囲を求める際に使う数値はデータの最小値と最大値でした。 そのためいくつかの問題が発生します。 まず、最小値と最大値だけを見ているので、他の値については無視することになっています。 そのため分布がどうなっているかを具体的に知ることはできません。 加えて、最小値・最大値が外れ値となっているある場合に、範囲が過大評価となってしまう恐れがあります。 そこで次に、データのすべての値がもつ情報を利用する分散と、分散を利用した標準偏差を求めることにします。\n\n\n3.2.2 分散と標準偏差\n分散とは、それぞれのデータが平均値を中心としてどのように散らばっているかを示すものです。 分散を求めることで、例えばペンギンの各個体の体長は全般的に均一な値をしているのか、特定の個体が平均値よりも特段高い（あるいは低い）のか、はたまた体長が高い個体と低いがバラバラにいるのかがわかるようになります。\n分散は次のように求めます。\n\n変数の値の平均値を出す\n変数の各値と平均値の差を求める（偏差と呼びます）\n2で求めた差を2乗する\nすべての値に対して1~3を繰り返し、合計する\n4をデータの数で割る\n\n各値と平均値の差を求めたあと、その合計を計算すると、どんなデータであっても合計は０になります。 平均値より小さい・大きい値との差を求めてその合計を出しているので、差を相殺することになっています。 これではばらつきを評価できません。 そこで分散を求める際には、その差を2乗し、値を足し合わせます。 ここまでの内容を整理すると次のように表現できます。\n\\[\n分散 = \\frac{変数の値と平均値の差の2乗の合計}{変数に含まれるデータ数} = \\frac{1}{n}\\sum_{i=i}^{n}{(x_i - \\bar{x})^2}\n\\]\n上記の式は標本分散を求める式となっています。 Rにおける分散の算出はvar()関数で行われますが、ここでの分散は不偏分散と呼ばれるもので データの数から１引いた値で割る点で異なります。 ここまでの内容をおさらいしてみましょう。\n\ndf <- \n  penguins |> \n  filter(species == \"Adelie\") |> \n  select(body_mass_g) |> \n  filter(!is.na(body_mass_g)) |> \n  slice_head(n = 5)\n\ndf <- \n  df |> \n  # 各値について偏差 deviation（平均よりもいくら大きいか小さいか）を求める\n  mutate(deviation = body_mass_g - mean(df$body_mass_g, na.rm = TRUE))\n\ndf\n\n\n\n\n\nbody_mass_g\ndeviation\n\n\n\n\n3750\n170\n\n\n3800\n220\n\n\n3250\n-330\n\n\n3450\n-130\n\n\n3650\n70\n\n\n\n\n\n\n\n# 偏差の合計は0になる\nsum(df$deviation)\n\n[1] 0\n\n\n\n# 偏差の値はプラスとマイナスが混ざる\ndf$deviation\n\n[1]  170  220 -330 -130   70\n\n# 偏差は2乗することでプラスの値のみになる\ndf$deviation^2\n\n[1]  28900  48400 108900  16900   4900\n\n\n\n# 分散\nsum(df$deviation^2) / nrow(df)\n\n[1] 41600\n\n# var()関数に対象の変数を直接与えて求めても良い\nvar(df$body_mass_g) * (nrow(df)-1) / nrow(df)\n\n[1] 41600\n\n\n\n# Rでは不偏分散\nvar(df$body_mass_g)\n\n[1] 52000\n\n# sum(df$deviation^2) / (nrow(df) - 1)\n\n合計が０になる差に対して2乗するのではなく、絶対値をとり、その合計を求めたものを平均偏差と呼びます。 また、分散について平方根を求めたものが標準偏差となります。 標準偏差は散らばりの具合を見るための指標となります。\n\n# 標準偏差\nsqrt(sum(df$deviation^2) / (nrow(df) - 1))\n\n[1] 228.0351\n\nsqrt(var(df$body_mass_g))\n\n[1] 228.0351\n\n\n標準偏差を求める際に平方根を利用する理由は、分散を求めたときに2乗したものを元に戻すためです。 具体的には2乗した場合に単位が変わってしまうものを元に戻す必要があるためです。 例えば、長さの単位としてセンチメートルで測ったものならば平方センチメートルとなり、面積の単位になってしまうのを防ぐ効果があります。\n\n\n\n標準偏差を導くまでの過程"
  },
  {
    "objectID": "summary_statistics.html#分布の姿を捉える",
    "href": "summary_statistics.html#分布の姿を捉える",
    "title": "3  データの特徴を捉える",
    "section": "3.3 分布の姿を捉える",
    "text": "3.3 分布の姿を捉える\nこれまで見てきたように、代表値やデータのばらつきを調べることでデータがどのような値を持っているのか、その分布の傾向を掴むことができるようになりました。 一方でまだ分布の姿そのものについては明らかではありません。 次の度数分布表やヒストグラム、箱ヒゲ図を作成することで、分布の姿を捉えることができるようになります。\n\n3.3.1 度数分布表\n実験や観測により値が得られたら、まずは度数分布表を作ることから始めると全体の分布の状況を理解しやすい傾向があります。 ある値がデータに含まれる数を度数どすうまたは頻度ひんどといいます。 度数分布表とはその名の通り、度数の分布を表形式にまとめたものを指します。 データに対する度数がどのように分布するかを示すかを表したものが度数分布表です。 度数によってすべてのデータに対して大まかな位置を集計することになるため、データの分布が明らかになります。\n動物のデータセットの分類群を例にすると、df_zoo$taxonで分類群の値（霊長類や鳥類）を確認し、各値をカウントして度数を求め、それを分類群ごとに集約するという手順をとります。\n\n\n\n分類群ごとに何種類の動物がいるか数えてみよう\n\n\n\ndf_zoo$taxon\n\n [1] \"食肉類\"   \"鳥類\"     \"食肉類\"   \"鳥類\"     \"霊長類\"   \"霊長類\"  \n [7] \"霊長類\"   \"食肉類\"   \"齧歯類\"   \"食肉類\"   \"鳥類\"     \"偶蹄類\"  \n[13] \"食肉類\"   \"食肉類\"   \"鳥類\"     \"食肉類\"   \"霊長類\"   \"鳥類\"    \n[19] \"鯨偶蹄類\" \"奇蹄類\"   \"齧歯類\"   \"鯨偶蹄類\"\n\n\n結果は次のようになります。\n\n# 度数、頻度を英語で frequency といいます\n# 度数が大きな分類群の順で表示するように sort = TRUE を指定しています\ncount(df_zoo, taxon, sort = TRUE, name = \"frequency\")\n\n\n\n\n\ntaxon\nfrequency\n\n\n\n\n食肉類\n7\n\n\n鳥類\n5\n\n\n霊長類\n4\n\n\n鯨偶蹄類\n2\n\n\n齧歯類\n2\n\n\n偶蹄類\n1\n\n\n奇蹄類\n1\n\n\n\n\n\n\n対象が質的変数の場合は頻度を簡単に求めることができます。 それでは量的変数の度数を求めるにはどうすれば良いでしょうか。 量的変数のうち、離散変数でサイコロの目のようにとりうる値が限られる際には質的変数と同じように考えることもできます。 一方で連続変数では質的変数や離散変数のように同じ値をとることが少ないです。 そのため連続変数や離散変数の度数を求めるときは、変数がとり得る値をいくつかの区間に分割した階級(class)を考えます。 このときの区間の幅を階級幅と呼びます。\nペンギンデータに含まれる体重を例として、まずは階級分けのために、まずは変数の最小値と最大値を調べましょう。 Rでは最小値・最大値を調べるのにrange()関数が利用できることを思い出しましょう。\n\nrange(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 2700 6300\n\n\n\n\nコードを表示\n# range()関数を使わないでmin()関数やmax()関数を使っても良い\nmin(penguins$body_mass_g, na.rm = TRUE)\n\n\n[1] 2700\n\n\nコードを表示\nmax(penguins$body_mass_g, na.rm = TRUE)\n\n\n[1] 6300\n\n\n最小値と最大値がわかったところで、次は階級と階級幅を設定します。 階級はデータ中のすべての値が含まれるようにします。 ペンギンデータの体重の最小値は2700、最大値は6300ですので、 2000から7000までの階級を設定しておきましょう。 この場合、階級幅を区切りが良い1000とすると階級数は5つあることになります。\nつづいて、階級ごとに含まれる値の件数を数えます。\n\nweight_freq <- \n  table(cut(penguins$body_mass_g, \n            breaks = seq(2000, \n                         7000, \n                         by = 1000),\n            dig.lab = 4))\n\n\ntibble::tibble(\n  class = names(weight_freq),\n  frequency = weight_freq)\n\n\n\n\n表 3.1: ペンギンデータの体重の度数分布表\n\n\nclass\nfrequency\n\n\n\n\n(2000,3000]\n11\n\n\n(3000,4000]\n159\n\n\n(4000,5000]\n111\n\n\n(5000,6000]\n59\n\n\n(6000,7000]\n2\n\n\n\n\n\n\n\n以上の手順が量的変数に対する度数分布表の求め方です。 ペンギンデータの体重についての度数分布表を作成することができました(表 3.1)。 3000から4000の区間に含まれる値が最も多く、その次に4000から5000の区間の値、そのほかの区間の値はわずかということがわかります。\n\n\n\n\n\n3.3.2 ヒストグラム\nここまではデータを要約する方法として、数値の要約や集計といった処理を行ってきました。 次に登場するヒストグラムはこれまでの例とは異なり、データをグラフで表現する手法になります。 データをグラフ上に可視化することで、データの分布を確認しつづ、データの特徴を素早く捉えることができるようになります。 こうしたグラフ表現はデータに対する説得力を増すためにも使われます。 それでは早速ヒストグラムの作り方を見ていきましょう。\nヒストグラムの元になるのは先ほど求めた度数分布表です。 ヒストグラムでは、グラフの横軸に興味のある変数の階級、縦軸に階級内に含まれる度数を示します。 階級ごとに柱を設け、柱の高さで度数を表現します。 このときに階級の間、つまり柱と柱の間隔を空けないようにします。\nペンギンの体重の度数分布表 (表 3.1) からヒストグラムを作成すると次のようになります(図 3.3)。\n\np <- \n  penguins |> \n  ggplot(aes(body_mass_g)) +\n  # ヒストグラムでは柱の階級をビン bin と呼びます\n  geom_histogram(bins = 5) +\n  ylab(\"Frequency\") +\n  xlab(\"Body mass (g)\") +\n  labs(title = \"ペンギンの体重のヒストグラム\")\n\np\n\n\n\n\n図 3.3: ペンギンの体重のヒストグラム\n\n\n\n\nヒストグラムによって一眼で3000から4000の区間の個体が多いことが読み取れます。 全体のデータの散らばりの程度についても大まかに把握することができます。\n次に、これまで見てきた代表値やばらつきを表す数値とヒストグラムの関係を見てみましょう。 データ全体の傾向を示すヒストグラムと、代表的な値の関係を見ることで、データに対する理解が深まります。\n\n\nコードを表示\np +\n  geom_vline(xintercept = mean(penguins$body_mass_g, na.rm = TRUE),\n             color = course_colors[3]) +\n  geom_vline(xintercept = median(penguins$body_mass_g, na.rm = TRUE),\n             color = course_colors[2]) +\n  geom_vline(xintercept = as.numeric(names(which.max(table(penguins$body_mass_g)))),\n             color = course_colors[1]) +\n  geom_label(aes(4400, 20), \n             label = \"平均値\", \n             color = course_colors[3],\n             show.legend = FALSE) +\n  geom_label(aes(4050, 50), \n             label = \"中央値\", \n             color = course_colors[2],\n             show.legend = FALSE) +\n  geom_label(aes(3600, 80), \n             label = \"最頻値\", \n             color = course_colors[1],\n             show.legend = FALSE)\n\n\n\n\n\n図 3.4: ペンギンの体重のヒストグラムと代表値の関係\n\n\n\n\n図 3.4 を見てわかることは、代表値の並びが小さい方から最頻値、中央値、平均値の順に並んでいることです。 ヒストグラムの形が左に長く伸びている（この様子を「裾を引いている」と言います）場合、代表値はこの順番に並ぶことが多くなります。\nヒストグラムを作成するときは、階級数がいくら設けられているかに注目します。 例えば同じデータであっても階級数が異なる場合、ヒストグラムの見た目は大きく異なります。 図 3.5 では、ペンギンの体重について階級数が2のときと30のときのヒストグラムをそれぞれ作成した図を表示しています。 階級数が少ないとデータの分布を把握するのが難しく、逆に階級数が多すぎるときもデータを要約し辛い図になってしまっています。\n\np1 <-\n  penguins |> \n  ggplot(aes(body_mass_g)) +\n  geom_histogram(bins = 2, fill = course_colors[1]) +\n  ylab(\"Frequency\") +\n  xlab(\"Body mass (g)\") +\n  labs(title = \"ペンギンの体重のヒストグラム。階級数2\")\np2 <-\n  penguins |> \n  ggplot(aes(body_mass_g)) +\n  geom_histogram(bins = 30, fill = course_colors[2]) +\n  ylab(\"Frequency\") +\n  xlab(\"Body mass (g)\") +\n  labs(title = \"ペンギンの体重のヒストグラム。階級数30\")\n\np1 + p2 + plot_layout(ncol = 2)\n\n\n\n\n図 3.5: 階級数によってヒストグラムの見た目は変わる\n\n\n\n\n\n\n\n\n\n\n階級幅の異なるヒストグラム\n\n\n\n階級の幅が一定でないヒストグラムが存在するよ。\n\n\n\n\n\n\n\n\n適切な階級数はどうやって決めるの？\n\n\n\n階級数を決める方法としては、最小値と最大値、データの範囲やデータ数などが参考になるよ。\nでも階級数によってヒストグラムの見た目が変わると\n適切かはわからないよね\nスタージェスの法則を用いる\n\n\n\n\n\n3.3.3 箱ヒゲ図\nヒストグラムの他に、グラフを用いたデータの散らばりを表現する方法として箱ヒゲ図 (図 3.6) があります。 四角い箱の上下に髭ひげが伸びているような図であることから箱ヒゲ図と呼ばれます。 「箱」と「ヒゲ」を使った簡単な図ですが、データの分布だけでなく、データを小さい方から並び替えてグループ分けを行ったときの代表的な3つの位置を表現する四分位点も合わせて表示できる図となっています。\n箱ヒゲ図の作成手順は次の通りです。 箱ヒゲ図を作成するときは、データの区間と四分位点を求めることが必要になります。\n\nまず最小値・最大値から、グラフの縦軸にデータの値が収まるような値を設定します。\n第1四分位点と第3四分位点の区間（四分位範囲）を「箱」としてグラフ上に描画します。\n中央値は第1四分位点と第3四分位点の間の値となりますので、箱の中に中央値を太い線で描きます。\n箱から箱の長さ（四分位範囲）の1.5倍を超す値を外れ値として点で描きます。\n箱の上端・下端から、外れ値でないものの最大値と最小値を線で結び「ヒゲ」を作ります。\n\n\n\n\n図 3.6: 箱ヒゲ図の見方と作り方\n\n\n動物データの体重について箱ヒゲ図を作成してみます (図 3.7)。 箱とヒゲについての意味を理解しておく必要がありますが、ヒストグラムのようにデータの分布を確認することができる図となっています。\nまた箱ヒゲ図の作成方法は上記のものの他に最大値と最小値をヒゲとして利用するものがあります。\n\ndf_zoo |> \n  ggplot(aes(y = body_length_cm)) +\n  geom_boxplot() +\n  labs(title = \"動物データの体重の箱ヒゲ図\")\n\n\n\n\n図 3.7: 動物データの体重の箱ヒゲ図\n\n\n\n\n箱ヒゲ図は複数データのばらつきを比較する際にも役立ちます。 ヒストグラムでは複数のデータを比較することが困難ですが、箱ヒゲ図では箱ヒゲを90度回転させて横に描画することで複数データの比較が容易になります。 図 3.8 は動物データの分類群ごとに体長の箱ヒゲ図を作成したものです。 箱ヒゲ図ではデータの散らばりが小さい場合には小さくなり、逆に散らばりが大きい時には大きくなります。 このことから、動物データに含まれる動物のうち、食肉類の体長は種の違いが大きく、霊長類は種のばらつきが小さいことが読み取れます。\n\n# 分類群ごとの箱ヒゲ図を描画\n# あらかじめ中央値を計算し、グラフ上では中央値の並びで分類群が表示されるように\n# 調整しています。\ndf_zoo |> \n  filter(!is.na(body_length_cm)) |> \n  group_by(taxon) |> \n  mutate(body_length_median = median(body_length_cm)) |> \n  ungroup() |> \n  mutate(taxon = forcats::fct_reorder(taxon, body_length_median)) |> \n  ggplot(aes(taxon, body_length_cm, color = taxon)) +\n  geom_boxplot() +\n  coord_flip() +\n  scale_colour_tokupon() +\n  guides(color = \"none\") +\n  labs(title = \"動物データの分類群ごとの体長の箱ヒゲ図\")\n\n\n\n\n図 3.8: 動物データの分類群ごとの体長の箱ヒゲ図。箱ヒゲ図を並べて描画することで複数のデータを比較しやすくなります。\n\n\n\n\n\n\n3.3.4 さまざまな分布の形\nヒストグラムや箱ヒゲ図で見てきたように、分布の形ががどのような形になっているかを意識することは、データ分析を進めていく際に重要です。 それは分布の形によってデータの特徴が異なるためです。 分布の形はその形に応じて次のような種類があります。\n\n中央に一つ峰がある山型の分布\n\n特に左右対称に近い形をした釣鐘型\n\nロングテール型(右に尻尾が長く伸びているような形)\n峰が２つ以上ある分布"
  },
  {
    "objectID": "summary_statistics.html#まとめと課題",
    "href": "summary_statistics.html#まとめと課題",
    "title": "3  データの特徴を捉える",
    "section": "3.4 まとめと課題",
    "text": "3.4 まとめと課題\n\nデータを要約する方法の一つに記述統計量がある。記述統計量は大きく次の2種類に分けられる\n\nデータ分析の目的の一つであるデータの要約を行う際に、平均値や中央値などの代表値が利用できる\nデータにはばらつきが存在し、そのばらつきを表現するための分散や標準偏差を計算できる\n\nヒストグラムを作って、いろいろな分布の形があることを確認しよう"
  },
  {
    "objectID": "summary_statistics.html#参考文献url",
    "href": "summary_statistics.html#参考文献url",
    "title": "3  データの特徴を捉える",
    "section": "3.5 参考文献・URL",
    "text": "3.5 参考文献・URL\n\n(編 1991)\n(神林博史 2019)\n(Peter Bruce, 訳, と 技術監修 2020)\n(日本統計学会 2020)\n(滋賀大学データサイエンス学部 2022)\n\n\n\n\n\nPeter Bruce, Peter Gedeck 著, Andrew Bruce, 訳, と 技術監修. 2020. データサイエンスのための統計学入門 : 予測、分類、統計モデリング、統計的機械学習とR/Pythonプログラミング. 第2版 版. オライリー・ジャパン. http://id.ndl.go.jp/bib/030715636.\n\n\n日本統計学会. 2020. データの分析 : 日本統計学会公式認定統計検定3級対応. 改訂版. 東京図書. http://id.ndl.go.jp/bib/030221455.\n\n\n滋賀大学データサイエンス学部長崎大学情報データ科学部 共編. 2022. データサイエンスの歩き方. 学術図書出版社. http://id.ndl.go.jp/bib/032035878.\n\n\n神林博史. 2019. 1歩前からはじめる「統計」の読み方・考え方. 第2版 版. ミネルヴァ書房. http://id.ndl.go.jp/bib/029539543.\n\n\n編. 1991. 基礎統計学. 1 (統計学入門). 東京大学出版会. http://id.ndl.go.jp/bib/000002123507."
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "",
    "text": "前章では、動物の体長や体重といった1つの変数を扱う方法を紹介しました。 データ分析では1つ以上の変数を同時に扱い、それらの変数について意味や関係を明らかにすることも目指します。 この章では体長と体重、体重と分類群、つまり2変数の関係を見ていくことにします。 2つの変数の関係を表す概念として相関の導入から、関係を表す手法である相関係数や散布図、クロス集計表について紹介します。 まずは関係という言葉自体について、データ分析の視点で扱われる2つの関係を説明します。\nこの章では次のRパッケージを利用します。 データセットとしてペンギンデータを引き続き利用します。"
  },
  {
    "objectID": "correlation.html#データ分析における2つの関係",
    "href": "correlation.html#データ分析における2つの関係",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.1 データ分析における2つの関係",
    "text": "4.1 データ分析における2つの関係\nデータ分析における「関係」は複数の変数がともに変化する状態を指します。 関係を扱うときには次に説明する因果関係と相関そうかん関係の2種類があり、似たものでありながら異なる状態を示すもので注意が必要です。\n本書の冒頭、データ分析の目的の中でみたように、 「ペンギンは翼の長い個体であれば口ばしの長くなる」はペンギンの体の部位の関係を示すものです。 こうした変数の間の関連性を相関関係といいます。 一方で、翼が長くなると口ばしが大きくなる、とするわけではありません。 逆も然りで、口ばしが大きくなれば翼が長くなるわけでもありません。 つまり、翼と口ばしの長さは、どちらかが大きくなればどちらかが大きくなることを説明するものではありません。 このような原因から結果を伴う状態を因果関係と言います。原因と結果の関係とも言えます。\nペンギンデータは野外に生息するペンギン個体の観測により得られたデータです。 各個体はここで観測していない年齢や食事の内容も異なるはずです。 その場合、翼や口ばしの長さに対する影響も当然変わると考えられます。 2つの変数の関連性は明らかですが、片方の変数が原因となり、もう片方の変数の値を決めている、 因果関係があるとは言えないのです。\n因果関係を明らかにするのは容易ではありません。 よくある例として、因果関係がないのに、観測されない要因により因果関係があるかのように推測される2変数の関係に擬似相関があります。\n擬似相関の例として有名な話があります。 ある街でのアイスクリームの売り上げが最も高い時期には、熱中症の搬送者数も最も多いことが指摘されました。 この時、アイスクリームの売り上げ増が熱中症の原因（あるいは結果）であると主張されましたが、 アイスクリームの売り上げや熱中症の増加も実際には、気温の高さが原因となっています。 気温について無視し、2つの変数の関係を議論すること、特に因果関係の有無を判断することは危険です。 熱中症患者の増加を抑えるために、アイスクリームの販売を規制するなどの誤った対策が取られてしまう恐れがあります。 気温について考慮せずに分析を進めてしまうと、見せかけの因果関係を発生させてしまいます。 ここでの気温のような観測されていない変数を潜在変数といいます。"
  },
  {
    "objectID": "correlation.html#相関-2つの変数の間の関係",
    "href": "correlation.html#相関-2つの変数の間の関係",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.2 相関: 2つの変数の間の関係",
    "text": "4.2 相関: 2つの変数の間の関係\n2つの量的変数の関係性を明らかにするために、相関という考え方を導入します。 ペンギンデータでは翼と口ばしの長さの関係を見ました。 これらの変数のように、互いの値が増えれば片方も増えるという傾向を示す関係を正の相関関係といいます。 一方、片方の変数の値が増えたときにもう片方の値が減少する場合、負の相関関係があるといいます。 この2つの関係に加えて、相関にはもう一つの関係があります。 それは変数の間に関係が見られない状態です。このことを無相関と呼びます。\n変数間の相関関係はグラフ上に表現すると傾向を掴みやすくなります。 2変数のデータの関係を表現するグラフとして散布図が利用できます。 散布図は対となる量的変数について、それぞれグラフの縦軸（y軸）と横軸（x軸）からなる平面上に値を投影します。 ある変数の値が2であるとき、もう片方の変数の値が3であればグラフの座標は\\((2,3)\\)となり、そこに点が打たれることになります。\nペンギンデータの翼の長さと口ばしの長さの関係を散布図で表してみましょう(図 1.1) 1。 まずはデータの一部を確認します。\n\npenguins |> \n  select(flipper_length_mm, bill_length_mm) |> \n  slice_head(n = 10)\n\n\n\nペンギンデータの口ばしと翼の長さの値 \n\n\nflipper_length_mm\nbill_length_mm\n\n\n\n\n181\n39.1\n\n\n186\n39.5\n\n\n195\n40.3\n\n\nNA\nNA\n\n\n193\n36.7\n\n\n190\n39.3\n\n\n181\n38.9\n\n\n195\n39.2\n\n\n193\n34.1\n\n\n190\n42.0\n\n\n\n\n\n\n一見すると傾向が掴みにくい2変数の関係もグラフに表すことで関係を捉えやすくなります。 散布図で横軸に示す口ばしの長さも、縦軸に示す翼の長さもいずれも値が大きいほど、もう片方の値も大きいことがわかります。\n散布図を用いて相関関係を整理してみましょう。 図 4.1 に相関関係を表わす3つの状態を示しました。 散布図の特徴として、縦軸と横軸に表示する変数を入れ替えた場合でも同様の相関関係を見ることができます。\n\nset.seed(123)\ndf_corr <- \n  tibble::tibble(\n  x = rnorm(100),\n  y = rnorm(100),\n  y_positive = 5 * x + rnorm(100, sd = 3),\n  y_negative = -5 * x + rnorm(100, sd = 4))\n\np1 <- \n  df_corr |> \n  ggplot(aes(x, y_positive)) +\n  geom_point() +\n  ylab(\"y\") +\n  labs(title = \"正の相関関係\")\np2 <- \n  df_corr |>  \n  ggplot(aes(x, y)) +\n  geom_point() +\n  labs(title = \"無相関\")\np3 <- \n  df_corr |> \n  ggplot(aes(x, y_negative)) +\n  geom_point() +\n  ylab(\"y\") +\n  labs(title = \"負の相関関係\")\n\np1 + p2 + p3 + \n  plot_layout(ncol = 3)\n\n\n\n\n図 4.1: 相関関係を示す3つの状態"
  },
  {
    "objectID": "correlation.html#つの変数の関係を数値的に評価する",
    "href": "correlation.html#つの変数の関係を数値的に評価する",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.3 2つの変数の関係を数値的に評価する",
    "text": "4.3 2つの変数の関係を数値的に評価する\n散布図によって、2つの変数の関係がありそうなのかなさそうなのか、おおよその傾向をつかむことができます。 しかし客観的に関係を評価するためには別の観点でデータを見る必要があります。 数値によって関係の強さを評価する方法として、共分散や相関係数があります。 これらの指標は、ある変数の値が変わったとき、もう片方の変数の値はどう変わるかを数値的に表現します。\n\n4.3.1 共分散\n2つの変数の関係を数値的に評価するとき、散布図に表示したように扱う変数を\\(x\\)と\\(y\\)の関係として見ていくことになります。 2つの変数の組を\\((x_1, y_1), ... (x_n, y_n)\\)、これは、一つ目の\\(x\\)変数の値、一つ目の\\(y\\)変数の値から、データに含まれる数までの\\(x\\)変数の値、データに含まれる数(\\(n\\)と表します)までの\\(y\\)変数の値を一つずつ見ることと同じ意味としたとき、共分散\\(Cov_{xy}\\)は次のように計算できます2。\n\\[\nCov_{xy} = \\frac{1}{n} \\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})\n\\]\n難しそうな記号\\(\\sum\\)（シグマ、日本語では総和そうわと読みます。）が出てきましたが、一つずつ進めていきましょう。 ここで出てきた\\(\\bar{x},\\bar{y}\\)は\\(x,y\\)の平均値を表します。 \\((x_i - \\bar{x})\\)ということは、\\(i\\)番目の\\(x\\)変数の値と\\(x\\)の平均値との差、すなわち偏差を求めることになります。 これは\\(x\\)だけでなく\\((y_i - \\bar{y})\\)とあるように\\(y\\)についても同様です。 \\(x\\)変数と\\(y\\)変数について偏差を求めたら、それを掛け合わせます。\nさて先ほど\\(i\\)番目の値について偏差を求めると言いましたが、 これは具体的に何番目の数値を示しているのでしょうか。 数学では、\\(x\\)についてのすべての値を足すときに\\(x_1 + x_2 + ... + x_n\\)と書けますが、これを簡略化したものとして \\(\\sum\\)を用います。 \\(\\sum\\)には上下に添字がつくことがあり、下の部分はどこから始めてということを意味する記号、上の部分にはどこまでかを示す記号を付け加えます。 そして\\(\\sum\\)の右側には足し合わされる内容を記述します。 このことを理解して先ほどの共分散の計算式に戻ります。\n共分散の式では、偏差の計算を行う際に\\(i\\)が使われています。 また\\(\\sum_{i=1}^{n}\\)を言語化すると「1から始めて\\(n\\)まで足す」となります。 つまり偏差を変数\\(x\\)、\\(y\\)のすべてのデータに対して求めて掛け合わせた値を足すことになります。 最後にデータの数\\(n\\)で割ることで共分散が計算されます。\n実際に値を見ながら計算を行いましょう。 ここでは単純にデータのすべてではなく2つのデータまでで共分散を求める、ということをやってみます。\n\n# ペンギンデータから2件分を取り出して共分散を求めます\ndf <- \n  penguins |> \n  slice_head(n = 2) |> \n  select(flipper_length_mm, bill_length_mm)\n\ndf\n\n\n\n\n\nflipper_length_mm\nbill_length_mm\n\n\n\n\n181\n39.1\n\n\n186\n39.5\n\n\n\n\n\n# 平均、偏差を求めます\ndf <- \n  df |> \n  mutate(across(everything(),.fns = mean, .names = \"{.col}_mean\")) |> \n  rowwise() |> \n  mutate(flipper_length_deviation = flipper_length_mm - flipper_length_mm_mean,\n         bill_length_deviation = bill_length_mm - bill_length_mm_mean)\n\ndf\n\n\n\n\n\n\n\n\n\n\n\n\n\nflipper_length_mm\nbill_length_mm\nflipper_length_mm_mean\nbill_length_mm_mean\nflipper_length_deviation\nbill_length_deviation\n\n\n\n\n181\n39.1\n183.5\n39.3\n-2.5\n-0.2\n\n\n186\n39.5\n183.5\n39.3\n2.5\n0.2\n\n\n\n\n\n\nこの値を式に当てはめます。\\(n\\)を2として置き換えます。\n\\[\nCov_{xy} = \\frac{1}{2} \\sum_{i=1}^{2}(x_i - \\bar{x})(y_i - \\bar{y}) \\\\\n=\\frac{1}{2} ( (181-183.5)(39.1-39.3)+(186-183.5)(39.5-39.3))　\\\\\n=0.5\n\\]\n\nとなります。Rでも同じ計算を実行します。\n\ndf |> \n  transmute(deviation_cross = flipper_length_deviation * bill_length_deviation) |> \n  ungroup() |> \n  pull(deviation_cross) |> \n  sum() / nrow(df)\n\n[1] 0.5\n\n\n先ほどの共分散の算出では、最終的にデータの件数\\(n\\)によって割りました。 しかしRの標準的な偏差を求める関数cov()は\\(n-1\\)で割る処理を行います。 この方法で求めれらる共分散は不偏共分散と呼ばれるものです。 得られたデータには偏りがあることを想定し、その偏りを除外する目的で1が引かれます。 話が難しくなりますので、これ以上の説明は参考文献に譲ります。\n\n# Rでは n -1 で割る不偏共分散が計算される\ncov(df$flipper_length_mm, df$bill_length_mm)\n\n[1] 1\n\n# nで割る共分散を知りたい場合\ncov(df$flipper_length_mm, df$bill_length_mm) * (nrow(df)-1) / nrow(df)\n\n[1] 0.5\n\n\n共分散と散布図の関係は、共分散の値が正のときには右上がりの散布図、共分散が負の値であれば散布図は右下がりとなります。 また散布図の中でデータがまんべんなく散らばっている場合、共分散は0に近い値となります。\n共分散は値が大きいほど2変数の関係が強いことを示します。しかし共分散の短所は変数の単位に依存して値が変わることです。\n単位の影響の例として、ミリメートル(mm)で記録されるペンギンデータの翼とくちばしの長さについて、 センチメートル(cm)に単位を変換した場合に共分散がどのように変化するのかを示します。 はじめに元のミリメートルでの共分散の値は次のようになります。\n\ndf_mm <- \n  penguins |> \n  select(flipper_length_mm, bill_length_mm) |> \n  purrr::set_names(c(\"flipper_length\", \"bill_length\"))\n\ncov(df_mm$flipper_length, df_mm$bill_length, use = \"complete.obs\")\n\n[1] 50.37577\n\n\n続いて測定単位をセンチメートルに変換した変数で共分散を求めてみます。\n\ndf_cm <- \n  df_mm |> \n  transmute(across(everything(), .fns = ~ .x / 10))\n\ncov(df_cm$flipper_length, df_cm$bill_length,  use = \"complete.obs\")\n\n[1] 0.5037577\n\n\n2つの変数の値の関係が変わった訳ではないのに、ミリメートルのときの共分散よりも小さな値になってしまいました。 これでは変数の関係を正しく評価できません。 そこでこの単位依存の問題を修正した尺度として相関係数が登場します。\n\n\n4.3.2 相関係数\n共分散の単位依存の性質は、共分散を各変数の標準偏差の積で割ることで解消できます。 これを相関係数と呼びます。 相関係数(\\(r\\))は次の式で定義されます。\n\\[\nr = \\frac{Cov_{xy}}{\\sqrt{\\frac{1}{n}\\sum_{i=i}^{n}{(x_i - \\bar{x})^2}} \\sqrt{\\frac{1}{n}\\sum_{i=i}^{n}{(y_i - \\bar{y})^2}}}\n\\]\n\n相関係数は2つの変数の間の直線的な関係の強さを評価する指標です。 -1以上から1以下の値をとり、変数の関係が強いほど、散布図にしたときに直線関係に近いものほど、絶対値が1に近づきます。\n相関係数にはいくつかの種類があり、中でもピアソンの積率相関係数が最も頻繁に利用されます3。 本書でも、相関係数といった時にはピアソンの積率相関係数を指して使います。\n\n\n\n\n\n\n相関係数の注意点\n\n\n\n相関係数はあくまでも変数の関係が直線関係にあることを仮定しているよ。 だから2変数間の関係が直線的でないときは適切な計算が行えないんだ。\nまた、相関係数は外れ値の影響を受けやすいよ。 外れ値とはデータに含まれる極端に小さい・大きい値のことだよ。 平均値が外れ値の影響を受けやすいということや、箱ヒゲ図を描画した際にも外れ値は他のデータと区別して表現していたことを思い出してね。 外れ値はデータ全体の傾向を大きく左右する影響があるから注意が必要なんだ。\n\n\nRでは相関係数の算出をcor()関数によって行います。 共分散の値を求めたとき同様、ペンギンデータの翼の長さとくちばしの長さについて相関係数を調べることにします。\n\ncor(df_mm$flipper_length, df_mm$bill_length, use = \"complete.obs\")\n\n[1] 0.6561813\n\n\nこの値は正の値であるので、正の相関であることがわかります。 一方で変数の関係の強さとしてはどの程度でしょうか。 相関係数の判断基準として 表 4.1 が一般的に使われています。 0.6561813は「やや強い相関がある」と言えることがわかりました。\n\n\nコードを表示\ntibble::tribble(\n  ~相関係数, ~相関の強さ,\n  \"\\u00b10.7以上\", \"とても強い\",\n  \"\\u00b10.4~0.7\", \"やや強い\",\n  \"\\u00b10.2~0.4\", \"弱い\",\n  \"\\u00b10.2以下\", \"ほとんどなし\")\n\n\n\n\n\n表 4.1: 相関係数の目安\n\n\n相関係数\n相関の強さ\n\n\n\n\n±0.7以上\nとても強い\n\n\n±0.4~0.7\nやや強い\n\n\n±0.2~0.4\n弱い\n\n\n±0.2以下\nほとんどなし\n\n\n\n\n\n\n\n続いて、相関係数が共分散の欠点を改善した点を確認しましょう。 共分散で求めたとき同様にペンギンデータの測定単位をセンチメートルに変換した2つのデータを用いて、測定単位の違いが相関係数に与える影響を調べてみます。\n\ncor(df_cm$flipper_length, df_cm$bill_length, use = \"complete.obs\")\n\n[1] 0.6561813\n\n\n相関係数では共分散とは異なり、測定単位の影響を受けない点が確認できました。 また、相関係数は標準化と呼ばれる処理を行った場合でもその影響を受けません。 このことから相関係数は標準化された値どうしの共分散とも考えられます。\n\n# 相関係数はデータの測定単位や標準化の有無に依存しない\ncor(scale(df_mm$flipper_length), scale(df_mm$bill_length), use = \"complete.obs\")\n\n          [,1]\n[1,] 0.6561813\n\ncor(scale(df_cm$flipper_length), scale(df_cm$bill_length), use = \"complete.obs\")\n\n          [,1]\n[1,] 0.6561813\n\n\n最後に繰り返しになりますが、相関係数は関係の強さを示す指標であって変数間の因果関係を示すものではありません。 どんな変数間であろうと相関係数は必ず出る点も気にしておきましょう。 2つの変数に対する関係として、片方の変数からもう片方の変数を説明することには回帰分析を実行する必要があります。"
  },
  {
    "objectID": "correlation.html#クロス集計表",
    "href": "correlation.html#クロス集計表",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.4 クロス集計表",
    "text": "4.4 クロス集計表\n質的変数の変数間の関係を調べる方法を紹介します。 ペンギンデータには、種の名前 species、生育する島の名前 island、性別 sex の3つの質的変数があります。 これらの質的変数間の関係を調べるためにクロス集計表を用います。\nクロス集計表では、対象の質的変数に含まれる件数をカウントし、表にまとめます。 表の行・列には変数の項目が並びます。 表 4.2 にペンギンデータにおける島ごとの種数を整理しました。\n\nlibrary(dplyr)\nlibrary(palmerpenguins)\npenguins |> \n  count(species, island) |> \n  tidyr::pivot_wider(names_from = island, values_from = n, values_fill = 0)\n\n\n\n\n表 4.2: ペンギンデータにおける島ごとの種数\n\n\nspecies\nBiscoe\nDream\nTorgersen\n\n\n\n\nAdelie\n44\n56\n52\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n124\n0\n0\n\n\n\n\n\n\n\nこの表を見るだけで次の事柄がわかります。\n\nアデリーペンギン Adelie は調査地のどの島にも生育する\nヒゲペンギン Chinstrap はDream島にだけ生育する\nジェンツーペンギン Gentoo はBiscoe島に多いがDreamやTorgersenには生育しない\n\nクロス集計表の利用によって1変数を調べただけではわからなかった質的変数の特徴を知ることができました。\nクロス集計表によって、データの比較が行いやすくなりましたが、 その差は本当にデータの性質を反映しているのでしょうか。 統計的な手法を用いることで、このような差の有無を判断できるようになります。 「なんとなく差がある」結果を統計的仮説検定を行うことで客観的に評価できるようになります。"
  },
  {
    "objectID": "correlation.html#まとめと課題",
    "href": "correlation.html#まとめと課題",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.5 まとめと課題",
    "text": "4.5 まとめと課題\n\n相関の例を探してみよう。擬似相関や因果関係とは違うか考えてみよう。"
  },
  {
    "objectID": "correlation.html#参考文献url",
    "href": "correlation.html#参考文献url",
    "title": "4  相関: 2変数の関係を調べる",
    "section": "4.6 参考文献・URL",
    "text": "4.6 参考文献・URL\n\n(編著 2012)\n(日本統計学会 2020)\n(嶋田正和 2017)\n(阿部真人 2021)\n(著, 監訳, と 訳 2020)\n\n\n\n\n\n嶋田正和阿部真人 著. 2017. Rで学ぶ統計学入門. 東京化学同人. http://id.ndl.go.jp/bib/027849441.\n\n\n日本統計学会. 2020. データの分析 : 日本統計学会公式認定統計検定3級対応. 改訂版. 東京図書. http://id.ndl.go.jp/bib/030221455.\n\n\n編著. 2012. 回帰分析入門 : Rで学ぶ最新データ解析. 東京図書. http://id.ndl.go.jp/bib/023292602.\n\n\n著Steven S.Skiena, 監訳, と 訳. 2020. データサイエンス設計マニュアル. オライリー・ジャパン. http://id.ndl.go.jp/bib/030185215.\n\n\n阿部真人. 2021. 統計学入門 : データ分析に必須の知識・考え方 : 仮説検定から統計モデリングまで重要トピックを完全網羅. ソシム. http://id.ndl.go.jp/bib/031803943."
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "5  グラフの作成",
    "section": "",
    "text": "これまでに本書の中でもデータのグラフ表現について、いくつかの例とともに紹介してきました。 データをグラフに表現するでは、ヒストグラムと箱ヒゲ図を紹介しました。 2変数のデータの関係を見る際は散布図が有効であることも、相関の中で解説しました。 グラフ表現がデータの要約、比較において優れる点について理解いただけたかと思います。\nデータ分析の歴史においては、ジョン・スノウによるコレラ死亡者の状態を示す地図やナイチンゲールのくさび形グラフなど、データそのものではなくデータをグラフに表現することが社会を動かす契機となることがありました。 データ可視化はデータの内容を訴える、コミュニケーションのツールとして機能します。\n一方で巷には粗悪なグラフも蔓延る点についても知っておかねばなりません。 数式によって導かれる分散や相関係数などとは異なり、グラフは人の意識をもって作成されます。 このとき情報操作のためのグラフが作られないとは限りません。 グラフに示されたデータを見ると、我々は意識せずにそれを受け入れる傾向にあります。 しかし情報を鵜呑みにすることは危険な行為です。\nグラフの良し悪しを判断できるようになるためには、数多くのグラフを見ること、審美眼を養うこと、そしてデータ表現について批判できるようになるが重要です。 ここではグラフが示されたときに正しく読み解く能力を身につけるとともに、グラフを作成する立場となった場合に、情報を正しく伝えられるか、誤解を招かない方法について紹介します。\n章の中で利用するパッケージを次のコマンドで読み込みます。\nまた次のコマンドの実行は作図の塗り分けを行う関数を読み込む処理です。 こちらも実行しておきましょう。"
  },
  {
    "objectID": "visualization.html#探索的データ解析",
    "href": "visualization.html#探索的データ解析",
    "title": "5  グラフの作成",
    "section": "5.1 探索的データ解析",
    "text": "5.1 探索的データ解析\n第二次世界大戦の後、1977年にジョン・テューキーが著書「Exploratory Data Analysis」のなかで探索的データ解析（探索的データ分析）の重要性を説きました。 その内容はいっさいの統計的な計算を介在させずに、データのもつ特徴を視覚化せようとする試みでした。 データ解析の第一歩として、計算を行わずにデータを眺める方法である探索的データ解析を提案したのです。\n探索的データ解析はデータ分析の第一歩となるだけでなく、次の一歩を踏み出すためにも役立ちます。 例えば散布図による関係の把握は、回帰モデル構築の足がかりになります。 与えられたデータセットからパターンやトレンドを探すことも分析に用いる手法を検討するのに効果的です。\nこれまでは数値によるデータ表現との比較としてデータ可視化の方法を見てきましたが、 次に示すのは要約統計量だけでは見えてこないデータの特性について、データ可視化の観点から説明する例となります。\n\n5.1.1 同じ統計量でも異なるグラフ: アンスコムの例\nデータを直接扱うのではなく、グラフ上に可視化することの重要性を説明する例として、アンスコムの例（アンスコムの数値例）がしばしば用いられます。これは1973年にフランク・アンスコムが紹介したもので、記述統計量や2変数の関係の強さを表す相関係数が小数点第二位まで同じ値となる場合であっても、中身のデータは大きく異なることを示すものです。\n表 5.1 にアンスコムが同じ統計量でも異なるグラフを作成する例として示したデータを表示します。\n\nanscombe\n\n\n\n\n表 5.1: アンスコムの例として示される統計量が同じ4種類のデータセット\n\n\nx1\nx2\nx3\nx4\ny1\ny2\ny3\ny4\n\n\n\n\n10\n10\n10\n8\n8.04\n9.14\n7.46\n6.58\n\n\n8\n8\n8\n8\n6.95\n8.14\n6.77\n5.76\n\n\n13\n13\n13\n8\n7.58\n8.74\n12.74\n7.71\n\n\n9\n9\n9\n8\n8.81\n8.77\n7.11\n8.84\n\n\n11\n11\n11\n8\n8.33\n9.26\n7.81\n8.47\n\n\n14\n14\n14\n8\n9.96\n8.10\n8.84\n7.04\n\n\n6\n6\n6\n8\n7.24\n6.13\n6.08\n5.25\n\n\n4\n4\n4\n19\n4.26\n3.10\n5.39\n12.50\n\n\n12\n12\n12\n8\n10.84\n9.13\n8.15\n5.56\n\n\n7\n7\n7\n8\n4.82\n7.26\n6.42\n7.91\n\n\n5\n5\n5\n8\n5.68\n4.74\n5.73\n6.89\n\n\n\n\n\n\n\nアンスコムの例を検証してみましょう。 一見異なる値をもつこれらのデータに対して、4種類のデータセットそれぞれで平均と分散、相関係数を求めてみます。\n\nanscombe_long <- \n  anscombe |> \n  tidyr::pivot_longer(\n    tidyselect::everything(),\n    names_to = c(\".value\", \"set\"),\n    names_pattern = \"(.)(.)\")\n\n# 記述統計量（平均と分散）の算出\n# setがデータセットの種類を示します\nanscombe_long |> \n  group_by(set) |> \n  summarise(across(.cols = c(x, y), .fns = list(mean = mean, sd = sd))) |> \n  summarise(across(.cols = contains(\"_\"), .fns = ~ round(.x, digits = 2)))\n\n\n\n\n\nx_mean\nx_sd\ny_mean\ny_sd\n\n\n\n\n9\n3.32\n7.5\n2.03\n\n\n9\n3.32\n7.5\n2.03\n\n\n9\n3.32\n7.5\n2.03\n\n\n9\n3.32\n7.5\n2.03\n\n\n\n\n\n# 同様にデータセットごとに相関係数を求めます\nanscombe_long |> \n  group_by(set) |> \n  group_modify(~ tibble::tibble(cor = cor.test(.x$x, .x$y)$estimate)) |> \n  ungroup() |> \n  mutate(cor = round(cor, digits = 2))\n\n\n\n\n\nset\ncor\n\n\n\n\n1\n0.82\n\n\n2\n0.82\n\n\n3\n0.82\n\n\n4\n0.82\n\n\n\n\n\n\n小数点第二位までは同じ値となることが確かめられました。 それでは問題となる散布図を見てみましょう。 2つの変数の直線回帰を行った際の回帰直線も同時に示します (図 5.1)。\n\nanscombe_long |> \n  group_by(set) |> \n  group_map(\n    ~ ggplot(.x, aes(x, y)) +\n  geom_point(color = course_colors[1]) +\n  geom_smooth(method = lm, se = FALSE, color = course_colors[2])) |> \n  wrap_plots(ncol = 2)\n\n\n\n\n図 5.1: アンスコムの例をグラフにしたもの。記述統計量が同じデータであっても散布図にすると見た目が異なる\n\n\n\n\n記述統計量が同じデータセットであっても、散布図の形は異なることが示されました。 また、外れ値が回帰直線に大きく影響している様子も見てとれます。 このようにアンスコムの例は、データを可視化することの重要性だけでなく、外れ値が統計量に与える影響の大きさも示しています。\n\n\n\n\n\n\nアンスコムサウルス\n\n\n\nアンスコムの例と同じく、記述統計量が同じでありながら散布図にすると異なる図を描くアルゴリズムをアルベルト・カイロが発見したよ。 これによって生成されたデータの一つを使うと次のような「恐竜」を描くことができるんだ。 この恐竜と同じ記述統計量となるデータを使ってさまざまな散布図が描画できるよ。\n\nlibrary(datasauRus)\n\ndatasaurus_dozen |> \n  filter(dataset == \"dino\") |> \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\ndatasaurus_dozen |> \n  filter(dataset != \"dino\") |> \n  ggplot(aes(x = x, y = y, colour = dataset)) +\n  geom_point() +\n  theme(legend.position = \"none\") +\n  facet_wrap(~dataset, ncol = 3)"
  },
  {
    "objectID": "visualization.html#分布を示すさまざまなグラフ",
    "href": "visualization.html#分布を示すさまざまなグラフ",
    "title": "5  グラフの作成",
    "section": "5.2 分布を示すさまざまなグラフ",
    "text": "5.2 分布を示すさまざまなグラフ\nデータの分布を示す際、ヒストグラムや箱ヒゲ図から一歩進んだグラフ表現を考えてみましょう。 実際問題として、ヒストグラムや箱ヒゲ図では階級や箱を利用することでデータを効率的に表現できていますが、 個々のデータについては一部の最小値・最大値や外れ値を除いてグラフ表現から無視することになっています。 この問題に対して、代替えとなるいくつかの可視化方法が検証されています。\n\n5.2.1 ヴァイオリンプロット\n同じ値があるときに横に広がります。\n上部の細長い糸巻き部とくびれのある胴部からなるヴァイオリンに似た形をすることがあることから、ヴァイオリンプロットと呼ばれます。\n\npenguins |> \n  ggplot(aes(species, bill_length_mm)) +\n  geom_violin()\n\n\n\n\n\n\n5.2.2 蜂群図\n蜂群図（ジッタープロットとも呼びます）はデータの分布の形とそのばらつきを構成する具体的な各値について説明します。 通常、ある質的変数についての量的変数の分布を示すのに用います。 横軸にはデータの値を点として投影します。このとき、もし複数の同じ値があるときには横に広がって表現されます。 点が集まっている様子が蜂の群を連想させることからこの名がついています。\n\nlibrary(ggbeeswarm)\npenguins |> \n  ggplot(aes(species, bill_length_mm)) +\n  geom_beeswarm()\n\n\n\n\n\n# ggplot2の標準関数にもgeom_jitter()関数が提供されています\npenguins |> \n  ggplot(aes(species, bill_length_mm)) +\n  geom_jitter()\n\n\n\n5.2.3 雨雲プロット\n\nlibrary(gghalves)\nlibrary(ggdist)\npenguins |> \n  ggplot(aes(species, bill_length_mm)) +\n  geom_half_point() +\n  geom_boxplot() + \n  stat_halfeye()"
  },
  {
    "objectID": "visualization.html#棒グラフ",
    "href": "visualization.html#棒グラフ",
    "title": "5  グラフの作成",
    "section": "5.3 棒グラフ",
    "text": "5.3 棒グラフ\n棒グラフ(図 5.2)はデータの大小を棒の高さで表現するグラフの種類です。 そのため、複数の項目間での値の違いを比較するのに適します。\n\npenguins |> \n  count(island) |> \n  ggplot(aes(island, n)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"島ごとのデータ件数\")\n\n\n\n\n図 5.2: ペンギンデータにおける島ごとのペンギンの記録数\n\n\n\n\n一般的な棒グラフは横軸に項目を並べ、縦軸に値を配置します。 これにより項目の値がそのまま棒の高さとして利用できます。\n棒グラフを作るときは項目の配置に気をつけることが多いです。 まず項目が多い、項目の名前が長い場合には、横軸に項目を並べた際に文字が重なってしまうことがあります。 その際は項目を横並びにするのではなく、縦に配置すると問題を回避できます。 このとき値は縦軸ではなく横軸に置かれます。 つまり軸の縦横を入れ替えて表示します。\nもう一つ並びを気にするのは、項目の並びに意味がある場合です。 例えば曜日ごとの値を棒グラフで示すのであれば、その並びは重要です。 月曜日の隣に金曜日が来ていては、見る方が混乱してしまいます。 この場合には月曜日ないし日曜日から始まって（グラフの左端にくる棒）週末が端に来るようにするのが適切です。 同様に、およそ南北に伸びる日本の都道府県や五十音順の項目を扱う際は並びに意味を持たせると良いでしょう。 そうでない場合、データの大きさの順にすると棒グラフが読みやすくなる印象があります。\n値が小さいものから大きいものへの並び替えを昇順、 値が大きいものから小さいものへの並び替えを降順と呼びます。 棒グラフの場合、左端がどちらでも良いですが、読む側は左から読み始める（のがほとんど？）ため 右肩下がり・上がりとなるようにすることがあります。\n棒グラフを見る・作る際の注意は、原点は0とするのが通常ということです。 原点が0でない棒グラフは誤解を招く恐れがあります。\n次の棒グラフ(図 5.3)は、いくつかの改善すべき点があります。 グラフを眺めてどのような修正が可能か検討してみましょう。\n\ndf_zoo |>\n  filter(!is.na(body_length_cm)) |> \n  ggplot(aes(name, body_length_cm, fill = taxon)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_tokupon() +\n  xlab(NULL) +\n  ylab(\"体長 (cm)\") +\n  labs(title = \"とくしま動物園で飼育される動物の標準的な体長\")\n\n\n\n\n図 5.3: 複数の項目を並べる棒グラフ。項目が多すぎて文字が潰れてしまっています\n\n\n\n\n図 5.4 が修正案です。 このグラフでは項目は横ではなく縦に配置する、項目の並びを工夫するを実践しました。 動物の名前の順序に意味はないので値の大きさで降順に並び替えています。 以上により、前のグラフ (図 5.3) よりも値と項目を眺めることが簡単になったと思います。\n\ndf_zoo |>\n  filter(!is.na(body_length_cm)) |> \n  ggplot(aes(forcats::fct_reorder(name, body_length_cm), body_length_cm, fill = taxon)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_tokupon() +\n  coord_flip() +\n  xlab(NULL) +\n  ylab(\"体長 (cm)\") +\n  labs(title = \"とくしま動物園で飼育される動物の標準的な体長\")\n\n\n\n\n図 5.4: 棒グラフの改善。\n\n\n\n\n\n5.3.1 積み上げ棒グラフ"
  },
  {
    "objectID": "visualization.html#折れ線グラフ",
    "href": "visualization.html#折れ線グラフ",
    "title": "5  グラフの作成",
    "section": "5.4 折れ線グラフ",
    "text": "5.4 折れ線グラフ\n系列グラフ\n主に時系列のデータを扱う際のグラフ表現となります。\n横軸に年や月といった時間要素、縦軸にデータの値を投影します。 さらにそれぞれのデータ点を線で繋げることで、データが時系列で変化する様子を表現します。"
  },
  {
    "objectID": "visualization.html#円グラフ",
    "href": "visualization.html#円グラフ",
    "title": "5  グラフの作成",
    "section": "5.5 円グラフ",
    "text": "5.5 円グラフ\n円グラフは、グラフに描いた円の中にデータの割合を表すグラフです。 質的変数がもつ割合に対して各値を円の領域（内角）に反映させることで、円全体で100%の構成を表現できます。 円グラフはデータ全体を占める内訳を表現するのに適したグラフです。 つまり、関心のある項目について全体と比較することを念頭にしています。\n円グラフは円の真上、時計の12時の位置から円の重心に引いた線を起点として、データの割合を角度で表します。 円の中に占める割合が大きい項目ほど、データの中での割合も多いことを示します。 例えば円グラフの半分、半円を占める値はデータ中の50%の値を意味します。\n円グラフを作る場合、起点が12時であること、項目の並びに意味がない場合には値の大きさの順番に配置することが肝心です。\n円グラフはデータ可視化の際に棒グラフとともにまず試される図の種類ですが、 円グラフを用いずに棒グラフやその他の方法で示すのが良い場面もあります。 それにはいくつかの理由があります。 第一に円グラフは複数のデータの比較に適さない点が挙げられます。 繰り返しになりますが、円グラフの利点はデータ全体に対する割合を示すことです。 一つの円の中での相対的な比較は可能ですが、別の円グラフを並べたとき、その比較は困難になります。 同様の理由から時系列を扱う場合には円グラフは適しません。 内訳について考えないグラフであれば一般的には棒グラフを選択することを勧めます。\n\n\ndf_zoo |> \n  count(taxon) |> \n  mutate(prop = n / sum(n) * 100) |> \n  ggplot(aes(x = \"\", y = prop, fill = taxon)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  scale_fill_tokupon() +\n  coord_polar(\"y\")\n\n\n\n\n考えなしに作った円グラフ\n\n\n\n\nこのグラフの改善点は\n値が大きい順にする\n分類群の数は7です。\n上位以外の分類群は「その他」としてまとめることにしましょう。 ここではカウントして1種だけしか含まれない「偶蹄類」と「奇蹄類」を「その他」として処理しました。\n「その他」は他の項目と違い、複数の項目を混ぜて集計した値です。 そのため円グラフの最後の部分を埋める位置に配置させるが適切です。\n\nlibrary(forcats)\ndf_zoo |> \n  mutate(taxon = fct_other(taxon, drop = c(\"偶蹄類\", \"奇蹄類\"), other_level = \"その他\")) |> \n  count(taxon) |> \n  mutate(prop = n / sum(n) * 100,\n         taxon = fct_rev(fct_relevel(fct_reorder(taxon, n), \"食肉類\", \"鳥類\", \"霊長類\", \"齧歯類\", \"鯨偶蹄類\", \"その他\"))) |> \n  arrange(taxon) |> \n  ggplot(aes(x = \"\", y = prop, fill = taxon)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  scale_fill_tokupon() +\n  coord_polar(\"y\", start = 0) +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  theme(axis.text = element_blank())\n\n\n\n\n3D円グラフはやめよう"
  },
  {
    "objectID": "visualization.html#地図表現",
    "href": "visualization.html#地図表現",
    "title": "5  グラフの作成",
    "section": "5.6 地図表現",
    "text": "5.6 地図表現\nカルトグラム\n\n\ndf_countries <-\n  countrycode::codelist |>\n  select(iso2c, cldr.name.ja) |>\n  janitor::clean_names()\n\nne_world <-\n  rnaturalearth::ne_countries(scale = 10, returnclass = \"sf\") |>\n  select(admin, name, pop_est, pop_year, iso_a2, continent)\n\nsf_zoo_conservation <- \n  ne_world |> \n  left_join(df_zoo_conservation |> \n              filter(name == \"フンボルトペンギン\") |> \n              tidyr::unnest(cols = occ) |> \n              select(code, presence),\n            by = c(\"iso_a2\" = \"code\")) |> \n  mutate(presence = tidyr::replace_na(presence, \"Absence\"))\n\n動物の分布を示す地図を作成してみましょう。\n\nggplot() +\n  geom_sf(data = sf_zoo_conservation, \n          aes(fill = presence), \n          size = 0.001) +\n  scale_fill_viridis_d()\n\n\n\n\n\nlibrary(mapview)\n\n\nmapview(sf_zoo_conservation, \n                 zcol = \"presence\")"
  },
  {
    "objectID": "visualization.html#まとめと課題",
    "href": "visualization.html#まとめと課題",
    "title": "5  グラフの作成",
    "section": "5.7 まとめと課題",
    "text": "5.7 まとめと課題\n\nさまざまなグラフの種類、グラフを構成する要素を紐解き、示されているデータを理解することができる\nグラフを作る際には（自分と）他人を騙す行為をしてはいけません\nここで紹介したグラフの他に、どんな種類のグラフがあるか探してみよう"
  },
  {
    "objectID": "visualization.html#参考文献url",
    "href": "visualization.html#参考文献url",
    "title": "5  グラフの作成",
    "section": "5.8 参考文献・URL",
    "text": "5.8 参考文献・URL\n\n(著 と 訳 1995)\n(松本健太郎 2017)\n([著] と 訳 2021)\n(著S. S. S., 監訳, と 訳 2020)\n(著 と 瓜生真也 2021)\n(アルベルト・カイロ著(薮井真澄訳) 2020)\n誤解を与える統計グラフ - Wikipedia https://ja.wikipedia.org/wiki/誤解を与える統計グラフ\nDownload the Datasaurus: Never trust summary statistics alone; always visualize your data http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html\n\n\n\n\n\n松本健太郎. 2017. グラフをつくる前に読む本 : 一瞬で伝わる表現はどのように生まれたのか. 技術評論社. http://id.ndl.go.jp/bib/028499054.\n\n\n[著]Andy Kirk, と 訳. 2021. データビジュアライゼーション : データ駆動型デザインガイド. 朝倉書店. http://id.ndl.go.jp/bib/031579212.\n\n\n著Steven S.Skiena, 監訳, と 訳. 2020. データサイエンス設計マニュアル. オライリー・ジャパン. http://id.ndl.go.jp/bib/030185215.\n\n\n著, と 瓜生真也三村喬生 訳. 2021. データ分析のためのデータ可視化入門. 実践Data Scienceシリーズ. 講談社. http://id.ndl.go.jp/bib/031219712.\n\n\nアルベルト・カイロ著(薮井真澄訳). 2020. グラフのウソを見破る技術 : マイアミ大学ビジュアル・ジャーナリズム講座. ダイヤモンド社. http://id.ndl.go.jp/bib/030421662.\n\n\n著, と 訳. 1995. 地図は嘘つきである. 晶文社. http://id.ndl.go.jp/bib/000002440327."
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "6  回帰問題に挑戦",
    "section": "",
    "text": "相関では2つの量的変数の関係を分析する方法として相関係数や散布図を紹介しました。\n回帰とは \\(y = f(x)\\)\n関数によって変数の間の関係を定式化\n直線の関数とみなし、\\(\\hat{Y}_i = a + bX_i\\)\n変数の関係を理解、\n予測ができるようになります。 例として、生まれてからのチンバンジーの日齢と体重\n前者の変数が後者の変数に影響していると想定できるため\n\\(x\\)を説明変数、\\(y\\)を目的変数と呼びます。\n変数間の関係、モデルとして組み立てる\nモデルによって説明する 直線的な関係を仮定する→線形モデル"
  },
  {
    "objectID": "regression.html#単回帰モデル",
    "href": "regression.html#単回帰モデル",
    "title": "6  回帰問題に挑戦",
    "section": "6.1 単回帰モデル",
    "text": "6.1 単回帰モデル\n線形回帰のうち、説明変数が一つの場合を単回帰といいます。 これに対して複数の説明変数によって目的変数の挙動を推定する線形回帰を重回帰と呼びますが、これについては本書では扱いません。 単回帰の基礎を抑えることで、重回帰への理解も深まります。\n\n\nコードを表示\nlm_res <- \n  lm(weight_kg ~ body_length_cm, data = df_zoo)\nlm_res\n\n\n\nCall:\nlm(formula = weight_kg ~ body_length_cm, data = df_zoo)\n\nCoefficients:\n   (Intercept)  body_length_cm  \n       -72.574           1.324  \n\n\nコードを表示\nsummary(lm_res)\n\n\n\nCall:\nlm(formula = weight_kg ~ body_length_cm, data = df_zoo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-90.587 -37.539  -6.151  25.768 151.495 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -72.5743    26.0890  -2.782   0.0133 *  \nbody_length_cm   1.3243     0.2109   6.280  1.1e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61.48 on 16 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.7114,    Adjusted R-squared:  0.6933 \nF-statistic: 39.43 on 1 and 16 DF,  p-value: 1.098e-05\n\n\n\n6.1.1 最小二乗法\n回帰直線によって２つの変数の関係をどの程度表現できているかを示す指標\n\n回帰直線からの差（残差）\n残差が小さいほど予測がうまく行っている\n\n残差を２乗し平均をとる –> 残差分散。値が小さいほど回帰直線による予測がうまくいくことを示す\n次に示すのは南極大陸に生育するペンギンの大きさを調べた観測データです。 それぞれの変数は次の意味をもちます（詳細は付録のデータセットを参照してください）。\n\nbill_length_mm: 口ばしの長さ。単位はミリメートル\nbody_mass_g: 体重。単位はグラム\n\n\n\n\nlm()関数\n\n\nコードを表示\nlm_res <- \n  lm(formula = body_mass_g ~ bill_length_mm, data = penguins)\n\nlm_res\n\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm, data = penguins)\n\nCoefficients:\n   (Intercept)  bill_length_mm  \n        362.31           87.42  \n\n\nコードを表示\nsummary(lm_res)\n\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1762.08  -446.98    32.59   462.31  1636.86 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     362.307    283.345   1.279    0.202    \nbill_length_mm   87.415      6.402  13.654   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 645.4 on 340 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3542,    Adjusted R-squared:  0.3523 \nF-statistic: 186.4 on 1 and 340 DF,  p-value: < 2.2e-16\n\n\npredict()関数\n\n\nコードを表示\nggplot(penguins, aes(bill_length_mm, body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n点の配置にもっともよくあてはまる回帰直線は、最小二乗法の原理で求めることができる\nデータ点に対して、最も適合する直線を引く\n二つのパラメータ、切片 \\(a\\) と傾き \\(b\\)を決定する\n残差 符号の影響を除くために二乗、さらに和をとって残差平方和\n\n\n6.1.2 決定係数\nモデルにおける予測値と実測値との相関係数を2乗した値。\n観測値の分散のうち予測によって説明される部分の割合を示す\n単純な線形回帰でどのくらい説明できるかを表す値\n\n\n6.1.3 95%信頼区間"
  },
  {
    "objectID": "regression.html#回帰と相関",
    "href": "regression.html#回帰と相関",
    "title": "6  回帰問題に挑戦",
    "section": "6.2 回帰と相関",
    "text": "6.2 回帰と相関"
  },
  {
    "objectID": "regression.html#まとめと課題",
    "href": "regression.html#まとめと課題",
    "title": "6  回帰問題に挑戦",
    "section": "6.3 まとめと課題",
    "text": "6.3 まとめと課題"
  },
  {
    "objectID": "regression.html#参考文献url",
    "href": "regression.html#参考文献url",
    "title": "6  回帰問題に挑戦",
    "section": "6.4 参考文献・URL",
    "text": "6.4 参考文献・URL\n\n(編著 2012)\n(嶋田正和 2017)\n(著 と 竹内惠行 2021)\n(著S. S. S., 監訳, と 訳 2020)\n\n\n\n\n\n嶋田正和阿部真人 著. 2017. Rで学ぶ統計学入門. 東京化学同人. http://id.ndl.go.jp/bib/027849441.\n\n\n編著. 2012. 回帰分析入門 : Rで学ぶ最新データ解析. 東京図書. http://id.ndl.go.jp/bib/023292602.\n\n\n著Steven S.Skiena, 監訳, と 訳. 2020. データサイエンス設計マニュアル. オライリー・ジャパン. http://id.ndl.go.jp/bib/030185215.\n\n\n著, と 竹内惠行濵田悦生 訳. 2021. 「誤差」「大間違い」「ウソ」を見分ける統計学. 共立出版. http://id.ndl.go.jp/bib/031563181."
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "7  分類問題に挑戦",
    "section": "",
    "text": "コードを表示\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "classification.html#ロジスティック回帰",
    "href": "classification.html#ロジスティック回帰",
    "title": "7  分類問題に挑戦",
    "section": "7.1 ロジスティック回帰",
    "text": "7.1 ロジスティック回帰"
  },
  {
    "objectID": "classification.html#主成分分析",
    "href": "classification.html#主成分分析",
    "title": "7  分類問題に挑戦",
    "section": "7.2 主成分分析",
    "text": "7.2 主成分分析\n\n\nコードを表示\nsubset(df_zoo, select = c(body_length_cm, weight_kg)) |> \n  dplyr::filter(!is.na(body_length_cm)) |> \n  prcomp(scale. = TRUE)\n\n\nStandard deviations (1, .., p=2):\n[1] 1.3577273 0.3956975\n\nRotation (n x k) = (2 x 2):\n                     PC1        PC2\nbody_length_cm 0.7071068 -0.7071068\nweight_kg      0.7071068  0.7071068"
  },
  {
    "objectID": "classification.html#クラスタリング",
    "href": "classification.html#クラスタリング",
    "title": "7  分類問題に挑戦",
    "section": "7.3 クラスタリング",
    "text": "7.3 クラスタリング"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "まとめ",
    "section": "",
    "text": "コースの内容は終わりです。お疲れさまでした。"
  },
  {
    "objectID": "summary.html#次の一歩",
    "href": "summary.html#次の一歩",
    "title": "まとめ",
    "section": "次の一歩",
    "text": "次の一歩\nデータ分析や統計グラフに興味をもった人のために、ウェブ上の学習資料やコンテンツ、政府や行政が行っているデータ分析のイベントを紹介します。\n統計グラフ全国コンクールは1953年から開催されている統計グラフの作成によるコンクルールです。過去の受賞作品を閲覧できるため、優れた統計グラフの例も知ることができます。 なお全国コンクルールは各都道府県で実施されるコンクールの優秀作品が評価対象となります。 そのため、まずは徳島県統計グラフコンクールへの応募を目指してはいかがでしょうか。 今年度(令和4年度)の募集締め切りは9月5日です。詳細は県のページを見てください。\n統計データ分析コンペティションは、高校生、大学生等を対象としたデータ分析コンペティションの一つです。SSDSE（教育用標準データセット）などを用いた統計データ分析内容をを論文として提出することになっています。統計データに対するアイデアと解析力が競われます。\n統計の日（10月18日）を中心に、統計に関する行事が行われます。\n\nその他の学習コンテンツ\n\nなるほど統計学園 https://www.stat.go.jp/naruhodo/index.html"
  },
  {
    "objectID": "summary.html#謝辞",
    "href": "summary.html#謝辞",
    "title": "まとめ",
    "section": "謝辞",
    "text": "謝辞\nこのコンテンツはGitHubでコードベースで管理され、誤字脱字や表記の修正について幅広く意見をいただくことを目指しています。 現在、次の方に改善案をいただいています。これらの方々に感謝します。 @niszet（順不同、敬称略）\nコンテンツの一部として使用した動物のシルエットはPHYLOPICがクリエイティブ・コモンズライセンスで提供するものです。以下に使用したシルエットのリンクを掲載します。\n\n\nhttp://phylopic.org/image/eedde61f-3402-4f7c-9350-49b74f5e1dba (Public Domain Mark 1.0)\nhttp://phylopic.org/image/7133ab33-cc79-4d7c-9656-48717359abb4 (CC 1.0)\nhttp://phylopic.org/image/071db0d0-20a2-4f1b-9c26-fa20db640664 (CC 1.0)\nhttp://phylopic.org/image/87c44856-307d-4d1a-84fd-ec54f8591f1a (CC 1.0)\nhttp://phylopic.org/image/dd7c7bc6-2c6d-48e4-860b-02bf37886b5b (CC 1.0)\nhttp://phylopic.org/image/9c234021-ce53-45d9-8fdd-b0ca3115a451 (CC 1.0)\nhttp://phylopic.org/image/44ead7ca-cc09-4469-8975-17827084abb3 (CC 1.0)\nhttp://phylopic.org/image/c97400f5-fab6-4452-ab32-1ee071848f31 (CC 1.0)\nhttp://phylopic.org/image/e4e306cd-73b6-4ca3-a08c-753a856f7f12 (CC 1.0)\nhttp://phylopic.org/image/c11b4873-aa21-4394-9f5e-6996033c379f (CC 1.0)\nhttp://phylopic.org/image/a0afbb0a-2bb8-4d69-999d-3ed3a09e9966 (CC 1.0)\nhttp://phylopic.org/image/02990f6d-82d3-45a9-b85e-99deb69d2a96 (CC 1.0)\nhttp://phylopic.org/image/75836dad-906e-4066-8518-ab60f0f96b73 (CC 1.0)\nhttp://phylopic.org/image/15020fb1-f6f7-432f-8905-8fd429627cc8 (CC 1.0)\nhttp://phylopic.org/image/7b8fb3d4-0cac-4552-8cd1-bd493b7de679 (CC 1.0)\nhttp://phylopic.org/image/7f02b605-c87b-4ec2-9e14-011f813c23a4 (CC 1.0)\nhttp://phylopic.org/image/b7344c53-6115-49cf-836d-ae71cc3853a8 (CC 1.0)\nhttp://phylopic.org/image/dcd56e52-c6e0-4831-824f-c65bee8875ca (CC 1.0)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献・URL",
    "section": "",
    "text": "Peter Bruce, Peter Gedeck 著, Andrew Bruce, 訳, and 技術監修. 2020.\nデータサイエンスのための統計学入門 :\n予測、分類、統計モデリング、統計的機械学習とR/Pythonプログラミング.\n第2版 ed. オライリー・ジャパン. http://id.ndl.go.jp/bib/030715636.\n\n\nアルベルト・カイロ著(薮井真澄訳). 2020. グラフのウソを見破る技術 :\nマイアミ大学ビジュアル・ジャーナリズム講座. ダイヤモンド社. http://id.ndl.go.jp/bib/030421662.\n\n\nマイケル・フレンドリーハワード・ウェイナー 著, and 訳. 2021.\nデータ視覚化の人類史 : グラフの発明から時間と空間の可視化まで.\n青土社. http://id.ndl.go.jp/bib/031736628.\n\n\n北川源四郎竹村彰通 編, and 内田誠一孝忠大輔. 2021.\n教養としてのデータサイエンス = Data Science as the Liberal\nArts. データサイエンス入門シリーズ. 講談社. http://id.ndl.go.jp/bib/031484010.\n\n\n嶋田正和阿部真人 著. 2017. Rで学ぶ統計学入門. 東京化学同人. http://id.ndl.go.jp/bib/027849441.\n\n\n日本統計学会. 2020. データの分析 :\n日本統計学会公式認定統計検定3級対応. 改訂版. 東京図書. http://id.ndl.go.jp/bib/030221455.\n\n\n松本健太郎. 2017. グラフをつくる前に読む本 :\n一瞬で伝わる表現はどのように生まれたのか. 技術評論社. http://id.ndl.go.jp/bib/028499054.\n\n\n松村優哉紀ノ定保礼. 2021. RユーザのためのRStudio〈実践〉入門 :\nTidyverseによるモダンな分析フローの世界. 改訂2版 ed. 技術評論社. http://id.ndl.go.jp/bib/031457544.\n\n\n江崎貴裕. 2020. 分析者のためのデータ解釈学入門 :\nデータの本質をとらえる技術. ソシム. http://id.ndl.go.jp/bib/030791751.\n\n\n滋賀大学データサイエンス学部長崎大学情報データ科学部 共編. 2022.\nデータサイエンスの歩き方. 学術図書出版社. http://id.ndl.go.jp/bib/032035878.\n\n\n石田基広. 2012. Rで学ぶデータ・プログラミング入門 = r Data\nProgramming with RStudio : RStudioを活用する. 共立出版. http://id.ndl.go.jp/bib/023999239.\n\n\n神林博史. 2019. 1歩前からはじめる「統計」の読み方・考え方.\n第2版 ed. ミネルヴァ書房. http://id.ndl.go.jp/bib/029539543.\n\n\n竹内薫. 2014. 統計の9割はウソ :\n世界にはびこる「数字トリック」を見破る技術. 徳間書店. http://id.ndl.go.jp/bib/025194412.\n\n\n編. 1991. 基礎統計学. 1 (統計学入門). 東京大学出版会. http://id.ndl.go.jp/bib/000002123507.\n\n\n編著. 2012. 回帰分析入門 : Rで学ぶ最新データ解析. 東京図書. http://id.ndl.go.jp/bib/023292602.\n\n\n著. 2018. データサイエンス入門. 岩波新書 新赤版 ; 1713.\n岩波書店. http://id.ndl.go.jp/bib/028897021.\n\n\n[著]Andy Kirk, and 訳. 2021. データビジュアライゼーション :\nデータ駆動型デザインガイド. 朝倉書店. http://id.ndl.go.jp/bib/031579212.\n\n\n著Steven S.Skiena, 監訳, and 訳. 2020.\nデータサイエンス設計マニュアル. オライリー・ジャパン. http://id.ndl.go.jp/bib/030185215.\n\n\n著, and 瓜生真也三村喬生 訳. 2021.\nデータ分析のためのデータ可視化入門. 実践Data Scienceシリーズ.\n講談社. http://id.ndl.go.jp/bib/031219712.\n\n\n著, and 竹内惠行濵田悦生 訳. 2021.\n「誤差」「大間違い」「ウソ」を見分ける統計学. 共立出版. http://id.ndl.go.jp/bib/031563181.\n\n\n著, and 訳. 1995. 地図は嘘つきである. 晶文社. http://id.ndl.go.jp/bib/000002440327.\n\n\n西内啓. 2013. 統計学が最強の学問である :\nデータ社会を生き抜くための武器と教養. ダイヤモンド社. http://id.ndl.go.jp/bib/024193446.\n\n\n阿部真人. 2021. 統計学入門 : データ分析に必須の知識・考え方 :\n仮説検定から統計モデリングまで重要トピックを完全網羅. ソシム. http://id.ndl.go.jp/bib/031803943."
  },
  {
    "objectID": "exercise.html",
    "href": "exercise.html",
    "title": "付録 A. 練習問題の答えと解説",
    "section": "",
    "text": "答えと解説を表示\n\n40人のクラスで平均点が48点のとき、点数が45点であっても上位20人の中に含まれることがある。\n平均値はデータの真ん中を表わす数値ではないよ。\n\n\nlibrary(ggplot2)\n\n# クラス中の40人のテストの点数（点数順）\nx\n\n [1] 16 24 27 31 32 32 33 33 36 36 37 38 39 40 40 42 43 43 43 44 44 45 46 46 48\n[26] 50 50 52 52 53 54 65 62 66 70 75 73 82 88 89\n\nmean(x) # クラスの平均点\n\n[1] 47.975\n\nmedian(x) # クラスの点数の中央値\n\n[1] 44\n\np <- \n  tibble::tibble(x = x) |> \n  ggplot(aes(x)) +\n  geom_density() +\n  xlim(0, 100) +\n  labs(title = \"40名のテスト点数の分布\")\n\np +\n  geom_vline(xintercept = median(x), color = course_colors[1]) +\n  geom_vline(xintercept = mean(x), color = course_colors[2]) +\n  geom_label(aes(mean(x), 0.01), \n             label = \"平均値\", \n             color = course_colors[2],\n             show.legend = FALSE) +\n  geom_label(aes(median(x), 0.02), \n             label = \"中央値\", \n             color = course_colors[1],\n             show.legend = FALSE)\n\n\n\n\n\nx[1:20]\n\n [1] 16 24 27 31 32 32 33 33 36 36 37 38 39 40 40 42 43 43 43 44\n\nx[21:40]\n\n [1] 44 45 46 46 48 50 50 52 52 53 54 65 62 66 70 75 73 82 88 89"
  },
  {
    "objectID": "exercise.html#章-動物データの代表値を計算しよう",
    "href": "exercise.html#章-動物データの代表値を計算しよう",
    "title": "付録 A. 練習問題の答えと解説",
    "section": "A.2 3章: 動物データの代表値を計算しよう",
    "text": "A.2 3章: 動物データの代表値を計算しよう\nここで紹介する関数は一部の例です。\n\n\nコードを表示\ndf_zoo <- \n  readr::read_csv(\"data-raw/tokushima_zoo_animals22.csv\", \n                col_types = \"ccdd_\")\n\nsummary(df_zoo)\n\n\n    taxon               name           body_length_cm     weight_kg     \n Length:22          Length:22          Min.   :  1.20   Min.   :  0.90  \n Class :character   Class :character   1st Qu.: 63.62   1st Qu.:  5.85  \n Mode  :character   Mode  :character   Median : 82.50   Median : 12.50  \n                                       Mean   :102.87   Mean   : 65.81  \n                                       3rd Qu.:133.00   3rd Qu.: 69.50  \n                                       Max.   :250.00   Max.   :410.00  \n                                       NA's   :4        NA's   :2       \n\n\nコードを表示\n# 中央値\nquantile(df_zoo$body_length_cm, na.rm = TRUE)[3]\n\n\n 50% \n82.5 \n\n\n\nskimr::skim(df_zoo)\npsych::describe(df_zoo)\nsummarytools::descr(df_zoo)"
  },
  {
    "objectID": "dataset.html",
    "href": "dataset.html",
    "title": "付録 B. データセット",
    "section": "",
    "text": "コードを表示\nlibrary(palmerpenguins)\npenguins"
  },
  {
    "objectID": "dataset.html#令和2年度-学校保健統計調査-都道府県別の身長体重の平均値及び標準偏差",
    "href": "dataset.html#令和2年度-学校保健統計調査-都道府県別の身長体重の平均値及び標準偏差",
    "title": "付録 B. データセット",
    "section": "B.2 令和2年度 学校保健統計調査 都道府県別の身長・体重の平均値及び標準偏差",
    "text": "B.2 令和2年度 学校保健統計調査 都道府県別の身長・体重の平均値及び標準偏差\ne-Statで公開されているファイルをRで処理しました。\n\n\nコードを表示\nif (file.exists(\"data-raw/令和2年度_学校保健統計調査_都道府県別_身長と体重_5歳.csv\") == FALSE) {\n  download.file(\"https://www.e-stat.go.jp/stat-search/file-download?statInfId=000032108465&fileKind=0\",\n                destfile = \"data-raw/r2_hoken_tokei_05.xls\")\n  df_hoken_toukei <- \n    readxl::read_xls(\"data-raw/r2_hoken_tokei_05.xls\", \n                     sheet = 1,\n                     range = \"B8:J55\",\n                     col_names = c(\"区分\",\n                                   paste(\"男\",\n                                         c(paste(\"身長\",\n                                                 c(\"平均値\", \"標準偏差\"),\n                                                 sep = \"_\"), \n                                           paste(\"体重\",\n                                                 c(\"平均値\", \"標準偏差\"),\n                                                 sep = \"_\")),\n                                         sep = \"_\"),\n                                   paste(\"女\",\n                                         c(paste(\"身長\",\n                                                 c(\"平均値\", \"標準偏差\"),\n                                                 sep = \"_\"), \n                                           paste(\"体重\",\n                                                 c(\"平均値\", \"標準偏差\"),\n                                                 sep = \"_\")),\n                                         sep = \"_\"))) |> \n    dplyr::mutate(区分 = stringr::str_squish(区分) |> \n                    stringr::str_remove_all(\"[:space:]\")) |> \n    dplyr::filter(区分 != \"全国\") |>  \n    dplyr::arrange(dplyr::desc(男_身長_平均値))\n  \n  df_hoken_toukei |> \n    readr::write_csv(\"data-raw/令和2年度_学校保健統計調査_都道府県別_身長と体重_5歳.csv\")\n} else {\n  df_hoken_toukei <-\n    readr::read_csv(\"data-raw/令和2年度_学校保健統計調査_都道府県別_身長と体重_5歳.csv\",\n                    col_types = \"cdddddddd\")\n}\n\n\n\ndf_hoken_toukei"
  },
  {
    "objectID": "dataset.html#とくしま動物園で飼育される動物の体の大きさと体重",
    "href": "dataset.html#とくしま動物園で飼育される動物の体の大きさと体重",
    "title": "付録 B. データセット",
    "section": "B.3 とくしま動物園で飼育される動物の体の大きさと体重",
    "text": "B.3 とくしま動物園で飼育される動物の体の大きさと体重\n\n\n名称: 動物データ\n\n\n\nコードを表示\nif (!file.exists(\"data-raw/tokushima_zoo_animals22.csv\")) {\n  library(dplyr)\n  library(rvest)\n  url <-\n    \"https://www.city.tokushima.tokushima.jp/zoo/gallery/ichiran.html\"\n  x <-\n    read_html(url)\n  # 2016-04-01\n  x |>\n    html_element(css = '#main > div.h1bg > div.update.clearfix > p') |>\n    html_text()\n  animals <-\n    x |>\n    html_elements(css = '#main > div.main_inner > div > p > span') |>\n    html_text() %>%\n    ensurer::ensure(length(.) == 22)\n  \n  # リスザルはリスザル属の総称\n  # ポニーは肩までの高さが147cm以下の馬の総称\n  df_zoo <-\n    tibble::tibble(\n      taxon = c(\"食肉類\", \"鳥類\", \"食肉類\", \"鳥類\", \"霊長類\",\n                \"霊長類\", \"霊長類\", \"食肉類\", \"齧歯類\", \"食肉類\",\n                \"鳥類\", \"偶蹄類\", \"食肉類\", \"食肉類\", \"鳥類\",\n                \"食肉類\", \"霊長類\", \"鳥類\", \"鯨偶蹄類\", \"奇蹄類\",\n                \"齧歯類\", \"鯨偶蹄類\"),\n      name = animals,\n      body_length_cm = c(63.5, 100, 64, 110, 85,\n                         66, 80, 168, 134, 250,\n                         130, 175, 31, NA_real_, 1.2,\n                         250, 35, 69, NA_real_, NA_real_,\n                         40, NA_real_),\n      weight_kg = c(6, 3.5, 5.4, 6.5, 60,\n                    10, 20, 80, 66, 225,\n                    # ホッキョクグマは平均体重のうち最大値を採用\n                    9, 220, 0.9, 30.3, 15,\n                    410, 1.1, 6, 140, NA_real_,\n                    1.5, NA_real_)) %>%\n    assertr::verify(dim(.) == c(22, 4))\n  df_zoo |> \n    readr::write_csv(\"data-raw/tokushima_zoo_animals22.csv\")\n} else {\n  df_zoo <-\n    readr::read_csv(\"data-raw/tokushima_zoo_animals22.csv\", \n                    col_types = \"ccdd\")\n}\n\n\nとくしま動物園で飼育される 22種の動物（2016年4月1日時点の情報）について体の大きさ（体長 cm）と体重（kg）をデータセット化したものです。 体長と体重については各動物のWikipediaのページを参照して記録しています。 原則として、各種の体長および体重の最大値を記録しています。 適当な値の記載がなかった項目については欠損値を与えています。\n\ndf_zoo\n\n\n\n  \n\n\n\nこのデータは GitHubリポジトリに保存してあります。\nhttps://github.com/uribo/tokupon_ds/blob/main/data-raw/tokushima_zoo_animals22.csv"
  },
  {
    "objectID": "dataset.html#とくしま動物園で飼育される動物の保全状況と生息地",
    "href": "dataset.html#とくしま動物園で飼育される動物の保全状況と生息地",
    "title": "付録 B. データセット",
    "section": "B.4 とくしま動物園で飼育される動物の保全状況と生息地",
    "text": "B.4 とくしま動物園で飼育される動物の保全状況と生息地\n\n名称: 動物保全状況データ\n\n\n\nコードを表示\nlibrary(magrittr)\ndf_zoo_name <- \n  tibble::tibble(\n    name = c(\"レッサーパンダ\", \"ホオジロカンムリヅル\", \n             \"コツメカワウソ\", \"カナダガン\", \"チンパンジー\", \n             \"シシオザル\", \"マントヒヒ\", \"ピューマ\", \"カピバラ\", \n             \"ライオン\", \"アフリカハゲコウ\", \"シロオリックス\", \n             \"ミーアキャット\", \"シンリンオオカミ\", \"アンデスコンドル\", \n             \"ホッキョクグマ\", \"リスザル\", \"フンボルトペンギン\", \n             \"ラマ\", \"ポニー\", \"モルモット\", \"ヒツジ\"),\n    scientific_name = c(\"Ailurus fulgens\", \"Balearica regulorum\", \n                        \"Aonyx cinerea\", \"Branta canadensis\", \"Pan troglodytes\",\n                        \"Macaca silenus\", \"Papio hamadryas\", \"Puma concolor\", \n                        \"Hydrochoerus hydrochaeris\", \"Panthera leo\",\n                        \"Leptoptilos crumeniferus\", \"Oryx dammah\", \"Suricata suricatta\", \n                        \"Canis lupus\", \"Vultur gryphus\",\n                        \"Ursus maritimus\", NA_character_, \"Spheniscus humboldti\",\n                        \"Lama glama\", NA_character_,\n                        \"Cavia porcellus\", \"Ovis aries\")) |> \n  dplyr::mutate(link = paste0(\"https://ja.wikipedia.org/wiki/\",\n                              dplyr::recode(name,\n                              `アンデスコンドル` = \"コンドル\",\n                              `ラマ` = \"リャマ\"))) %>% \n  dplyr::filter(!is.na(scientific_name)) %>% \n  assertr::verify(dim(.) == c(20, 3))\n\nif (file.exists(\"data-raw/tokushima_zoo_animals_conservation_status.rds\") == FALSE) {\n  library(rredlist)\n  animal_scname <- \n    df_zoo_name |> \n    purrr::pluck(\"scientific_name\")\n  \n  if (file.exists(\"data-raw/redlist_search_raw.rds\") == FALSE) {\n    result_red_list_search <-\n      animal_scname |> \n      purrr::map_dfr(\n        ~ tibble::as_tibble(purrr::pluck(rredlist::rl_search(name = .x), \n                                         \"result\")))\n    result_red_list_search |> \n      readr::write_rds(\"data-raw/redlist_search_raw.rds\")    \n  } else {\n    result_red_list_search <-\n      readr::read_rds(\"data-raw/redlist_search_raw.rds\")\n  }\n  if (file.exists(\"data-raw/redlist_occ_country_raw.rds\") == FALSE) {\n    result_red_list_occ <- \n      animal_scname |> \n      purrr::set_names(animal_scname) |>\n      purrr::map_dfr(~ tibble::as_tibble(purrr::pluck(rredlist::rl_occ_country(name = .x), \n                                                      \"result\")),\n                     .id = \"scientific_name\")\n    result_red_list_occ |> \n      readr::write_rds(\"data-raw/redlist_occ_country_raw.rds\")\n  } else {\n    result_red_list_occ <- \n      readr::read_rds(\"data-raw/redlist_occ_country_raw.rds\")\n  }\n  result_red_list_occ <- \n    result_red_list_occ |> \n    dplyr::select(!c(distribution_code)) |> \n    tidyr::nest(occ = c(code, country, presence, origin))\n  \n  df_red_list_information <-\n    result_red_list_search |>\n    dplyr::select(\n      taxonid,\n      scientific_name,\n      main_common_name,\n      category,\n      population_trend,\n      tidyselect::ends_with(\"_system\"),\n      tidyselect::starts_with(\"elevation_\"),\n      tidyselect::starts_with(\"depth_\")) |>\n    tidyr::nest(ecosystem = tidyselect::ends_with(\"_system\"),\n                limitation = c(tidyselect::ends_with(\"upper\"), tidyselect::ends_with(\"lower\"))) |>\n    dplyr::left_join(result_red_list_occ, by = \"scientific_name\")\n  df_zoo_conservation <- \n    df_zoo_name |> \n    dplyr::select(!link) |> \n    dplyr::left_join(df_red_list_information, by = \"scientific_name\") %>%\n    assertr::verify(dim(.) == c(20, 9))\n  df_zoo_conservation |> \n    readr::write_rds(\"data-raw/tokushima_zoo_animals_conservation_status.rds\")\n} else {\n  df_zoo_conservation <-\n    readr::read_rds(\"data-raw/tokushima_zoo_animals_conservation_status.rds\")\n}\n\n\n動物データのうち、生物種名（学名）が判別可能な20種についての生息地とその保全状況を 示すデータセットです。国際自然保護連合(IUCN)が指定するIUCNレッドリストからデータを取得しています。\n\ndf_zoo_conservation"
  },
  {
    "objectID": "r_intro.html",
    "href": "r_intro.html",
    "title": "付録 C. Rのイロハ",
    "section": "",
    "text": "オブジェクト、クラス"
  },
  {
    "objectID": "r_intro.html#rrstudioのインストール",
    "href": "r_intro.html#rrstudioのインストール",
    "title": "付録 C. Rのイロハ",
    "section": "C.1 R、RStudioのインストール",
    "text": "C.1 R、RStudioのインストール"
  },
  {
    "objectID": "r_intro.html#電卓として使ってみよう",
    "href": "r_intro.html#電卓として使ってみよう",
    "title": "付録 C. Rのイロハ",
    "section": "C.2 電卓として使ってみよう",
    "text": "C.2 電卓として使ってみよう\n値をオブジェクトに保存することを代入と言います。 代入は <- を使って実行します。 代入した値はオブジェクトを呼び出すこと（参照と言います）によって取り出せます。 また、オブジェクトのコピーや上書きといった処理も可能です。\n\n# 1 + 1の計算結果をオブジェクトxに代入（保存）\nx <- 1 + 1\n\n\n# オブジェクトの呼び出し（参照）\nx\n\n[1] 2\n\n# オブジェクトのコピー\ny <- x\ny\n\n[1] 2\n\n# オブジェクトの上書き\nx <- 9 * 9\n\n\nx\n\n[1] 81\n\ny\n\n[1] 2\n\n\n\nC.2.1 値を比較する\n\n\nC.2.2 関数\n関数には\n引数ひきすうを指定できるものがあります。\n引数名 = 値 の関係で記述します。複数の引数を利用する場合、カンマ , を使って引数を区切ります。\n\n# 平方根\nsqrt(4)\n\n[1] 2\n\nclass(sqrt)\n\n[1] \"function\"\n\nx <- c(1, 3, NA, 5)\nmean(x)\n\n[1] NA\n\n# na.rm引数にTRUEを指定し、欠損を無視した状態で平均を求めます\nmean(x, na.rm = TRUE)\n\n[1] 3"
  },
  {
    "objectID": "r_intro.html#データフレーム",
    "href": "r_intro.html#データフレーム",
    "title": "付録 C. Rのイロハ",
    "section": "C.3 データフレーム",
    "text": "C.3 データフレーム\n\ndata.frame(\n  `名前` = c(\"サトウさん\", \"ウチダさん\", \"エンドウさん\", \"ミシマさん\"),\n  `身長` = c(153.3, 162.8, 145.1, 121.7),\n  `体重` = c(48.4, 59.0, 47.2, 39.1))\n\n\n\n\n\n名前\n身長\n体重\n\n\n\n\nサトウさん\n153.3\n48.4\n\n\nウチダさん\n162.8\n59.0\n\n\nエンドウさん\n145.1\n47.2\n\n\nミシマさん\n121.7\n39.1\n\n\n\n\n\n\n\nC.3.1 データの読み込み\ncsv\n\n\nC.3.2 データのコピー\n表計算ソフトウェアに格納されているデータをRに読み込ませる方法を紹介します。"
  },
  {
    "objectID": "r_intro.html#パッケージの利用",
    "href": "r_intro.html#パッケージの利用",
    "title": "付録 C. Rのイロハ",
    "section": "C.4 パッケージの利用",
    "text": "C.4 パッケージの利用\nRには標準的に十分な機能が用意されていますが、パッケージと呼ばれる機能拡張を導入することで何倍も便利で使いやすいものになる可能性を秘めています。\nパッケージには関数やデータセットが含まれます。 本書でも利用したデータセットの一つであるペンギンデータもpalmerpenguinsパッケージが提供するデータです。 このほか、本書のRプログラムによる作図はggplot2パッケージとその拡張パッケージを利用して作成されています。\nパッケージを利用するには、まず利用するRの環境にインストールを行う必要があります。 Rパッケージのインストールは次のようにinstall.packages()関数を用いて実行します。\n\n# ggplot2パッケージをインストール。\n# ggplot2の部分を任意のパッケージ名に書き換えて好みのパッケージをインストールできます\ninstall.packages(\"ggplot2\")\n\nインストールされたパッケージはlibrary()関数で利用可能な状態にします。 この関数の実行により、パッケージが提供する関数やデータが使用できるようになります。\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "r_intro.html#参考文献url",
    "href": "r_intro.html#参考文献url",
    "title": "付録 C. Rのイロハ",
    "section": "C.5 参考文献・URL",
    "text": "C.5 参考文献・URL\n\n(石田基広 2012)\n(松村優哉 2021)\n\n\n\n\n\n松村優哉紀ノ定保礼. 2021. RユーザのためのRStudio〈実践〉入門 : tidyverseによるモダンな分析フローの世界. 改訂2版 版. 技術評論社. http://id.ndl.go.jp/bib/031457544.\n\n\n石田基広. 2012. Rで学ぶデータ・プログラミング入門 = R Data Programming with RStudio : RStudioを活用する. 共立出版. http://id.ndl.go.jp/bib/023999239."
  }
]